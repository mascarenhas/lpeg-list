\documentclass[12pt]{article}

\usepackage{sbc-template}

\usepackage{graphicx,url}

%\usepackage[brazil]{babel}   
\usepackage[latin1]{inputenc}  
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{alltt}


\newcommand{\Pow}{\, \widehat{} \,\,}
\newcommand{\Match}[3]{\mathrm{match} \;\, #1\;#2\;#3}
\newcommand{\Matchf}[4]{\mathrm{match} \;\, #1\;#2\;#3\;#4}
\newcommand{\Matchl}[4]{\mathrm{match}_L \;\, #1\;#2\;#3\;#4}
\newcommand{\Matchlk}[5]{\mathrm{match}_L \;\, #1\;#2\;#3\;#4\;#5}
\newcommand{\Matchrec}[5]{\mathrm{match} \;\, #1\;#2\;#3\;#4\;#5}
\newcommand{\Nothing}{{\tt fail}}
\newcommand{\Just}[1]{\mbox{#1}}
\newcommand{\Justc}[2]{(\mbox{#1},\,#2)}
\newcommand{\Striple}[3]{(#1,\,#2,\,#3)}
\newcommand{\Sstate}[4]{\langle#1,\,#2,\,#3,\,#4\rangle}
\newcommand{\Sstatec}[5]{\langle#1,\,#2,\,#3,\,#4,\,#5\rangle}
\newcommand{\Sfail}[1]{\mbox{\bf Fail}{\langle#1\rangle}}
\newcommand{\Sstep}[4]{#1 & \xrightarrow{#2} & #3 & #4\\}
\newcommand{\Sstepp}[4]{#1 \xrightarrow{#2} #3\\}
\newcommand{\Ia}[2]{\mbox{{\scriptsize {\tt #1} $#2$}}}
\newcommand{\Iaa}[3]{\mbox{{\scriptsize {\tt #1} $#2$ $#3$}}}
\newcommand{\Fail}{\mbox{\bf Fail}}
\newcommand{\Hd}[1]{\mbox{hd}(#1)}
\newcommand{\Sub}{{s}}
\newcommand{\Subb}{{s_1}}
\newcommand{\Subi}{\Sub [i]}
\newcommand{\Subbi}{\Subb [i]}
\newcommand{\MathN}[1]{\mbox{\emph{#1}}}
\newcommand{\Nat}{\mbox{\bf N}}
\newcommand{\myarrow}{\xrightarrow{\;\;\;\;\;}}
\newcommand{\myarrowstar}{\xrightarrow{\;\;*\;\;}}
\newcommand{\fivespaces}{\;\;\;\;\;}
\newcommand{\tenspaces}{\fivespaces\fivespaces}
\newcommand{\twentyspaces}{\tenspaces\tenspaces}
\newcommand{\thirtyspaces}{\twentyspaces\tenspaces}
\newcommand{\fortyspaces}{\twentyspaces\twentyspaces}
\newcommand{\interf}{\fivespaces}
\newcommand{\mylabel}[1]{\ \ \mathbf{(#1)}}
\newcommand{\chmath}[1]{\mbox{`#1'}}

\newcommand{\Eval}[1]{\mathrm{eval} \; #1}
\newcommand{\Esimple}[2]{\mathrm{esimp} \; #1\;#2}
\newcommand{\Efunction}[2]{\mathrm{efunc} \; #1\;#2}
\newcommand{\Efold}[2]{\mathrm{efold} \; #1\;#2}
\newcommand{\Cconst}[1]{\mathrm{Cconst} \; #1}
\newcommand{\Csimple}[2]{\mathrm{Csimple} \; (#1,\,#2)}
\newcommand{\Cfunc}[1]{\mathrm{Cfunc} \; #1}
\newcommand{\Cfold}[1]{\mathrm{Cfold} \; #1}
\newcommand{\Cclose}[1]{\mathrm{Cclose} \; #1}
\newcommand{\Emptyl}{\{\}}
\newcommand{\Mapl}{map_{s \rightarrow l}}
\newcommand{\Pcap}[2]{\langle#1,\,#2\rangle}
\newcommand{\Pcapp}[3]{\langle#1,\,#2,\,#3\rangle}

\newtheorem{proposition}{Proposition}

\sloppy

\title{Efficient List Matching for PEGs}

\author{Sérgio Medeiros\inst{1}, Fabio Mascarenhas\inst{1}, Roberto Ierusalimschy\inst{1} }


\address{Department of Computer Science -- PUC-Rio -- Rio de Janeiro -- Brazil
  \email{\{smedeiros,roberto\}@inf.puc-rio.br, mascarenhas@acm.org}
}

\begin{document} 

\maketitle

\begin{abstract}
Parsing Expression Grammars (PEGs) are a recognition-based foundation
for describing syntax that renewed interest in top-down parsing
approaches. We extend the definition of PEGs to support the matching
of lists, presenting a corresponding operational semantics and an
implementation of PEGs supporting this feature. The implementation
is based on a virtual parsing machine, where each PEG  
has a corresponding program that is executed by the machine,
and new programs are dynamically created and composed. 
We show how to transform PEGs to parsing machine programs, and
give a correctness proof of our transformation.
We discuss the use of semantic actions, and shows the efficiency
of our machine comparing it with other PEG-based tool.
\end{abstract}

%\keywords{parsing machine, Parsing Expression Grammars, pattern matching} % NOT required for Proceedings

\section{Introduction}

Parsing Expression Grammars (PEGs) are a formalism for language recognition,
proposed by Ford~\cite{ford:peg}, which renewed interest in top-down parsing
approaches. The PEG formalism gives a convenient syntax for describing top-down
parsers for unambiguous languages. 

LPEG~\cite{roberto:lpeg, lpeg} is a pattern-matching tool based on PEGs
for the Lua language~\cite{pil2}. LPEG uses PEGs to describe patterns
instead of the more popular Perl-like "regular expressions" (regexes). 
PEGs offer a way of writing patterns that is simple for
small patterns, while providing better organization for the more complex
patterns.

The implementation of LPEG uses a \emph{virtual parsing machine},
where each pattern translates to a program for this machine~\cite{dls:lpeg}.
These programs are built at runtime,
and can also be dynamically composed into bigger programs (that
represent bigger patterns). This piecemeal construction
of programs fits both the dynamic nature of Lua programming, and the
composability of the PEG formalism.

%The parsing machine is also fast, with the performance of LPEG being similar
%to the performance of other parser and pattern-matching tools. Moreover,
%the machine has a very simple model, which makes its implementation easy,
%and seems a very good candidate for a Just-In-Time (JIT) compiler.

This paper is a continuation of a previous work~\cite{dls:lpeg}, where we 
have presented the full formal specification of the parsing machine, plus the
proof of correctness of the transformation between PEG patterns and programs
of our machine.

In the present work, we extend the definition of PEGs to support the matching
of lists. Accordingly, we extend the operational semantics of PEGs presented
previously, and also extend the instruction set of the parsing machine,
proving the transformation between PEG patterns and programs of our machine
is still correct.

We also discuss the use of semantic actions in the realm of PEGs. We extend PEGs
again in order to support the use of semantic actions, and present how semantic
actions are performed by the parsing machine. During the matching, the machine
does not actually perform the actions, but only captures enough information, so
later (after the matching) it can produce values from the captured information.

The performance of LPEG is compared with OMeta~\cite{warth:ometa}, a language based
on an extension of PEGs which supports the matching of lists. Our benchmarks show
LPEG is almost $10$ times faster than OMeta.

The rest of this paper is organized as follows: Section~\ref{sec:machine} reviews
briefly some PEG concepts and describes the virtual machine and its new operational
semantics supporting lists; Section~\ref{sec:equivalence} proves the transformation
between PEGs and their corresponding programs is correct; Section~\ref{sec:optimizations}
describes a new set of list-specific instructions for the machine;
Section~\ref{sec:captures} gives an operational semantics for semantic actions
and shows how the machine perform these actions; Section~\ref{sec:related} discusses some
related work and presents a benchmark comparing LPEG with OMeta; finally,
Section~\ref{sec:conclusions} summarizes our results.


\section{Extending PEGs with Lists}
\label{sec:machine}

In~\cite{dls:lpeg}, we have described a \texttt{match} relation for PEGs, 
where \texttt{match} was defined as
$\mathrm{Grammar} \times \mathrm{Pattern} \times \Sigma^{*} \times \mathcal{N} \times (\mathcal{N} \cup \{\Nothing\})$.
Given a PEG grammar, a pattern, a subject and a position (position $1$ indicates the beginning of the subject),
if the match succeeds, the relation gives us the position of the subject after the match,
otherwise, if the match fails, it gives us the result \emph{\Nothing}.

We are going to define a new relation $\texttt{match}_L$, which operates on lists.
An empty list is represented as \Emptyl. Given a character $\chmath{c}$, and a list
$l$, by using the $cons$ operator we can build a new list $l^\prime$, which is a list
whose head is $\chmath{c}$, and whose tail is $l$. Given two lists $l_1$ and $l_2$,
we can also use the $cons$ operator to build a new list $l^\prime$, which is a list
whose head is $l_1$, and whose tail is $l_2$. 

%We have that Below there is an example of a list,
%where its elements are separated by commas: \\
%\begin{math}
%\{\chmath{a}, {\chmath{b}}, {\chmath{c}, \chmath{d}}, \chmath{e}\}
%\end{math}

The length of a list $l$, which we will represent as $|l|$, is the number of elements
of $l$. The empty list has length $0$, and a nonempty list $l$ has length $1$ plus the
length of its tail. If $h$ and $t$ are respectively the head and the tail of a list $l$,
we can represent $l$ as $h:t$. We can concatenate two lists by using the operator $++$. 

We will then define $\texttt{match}_L$ as a relation
$\mathrm{Grammar} \times \mathrm{Pattern} \times \mathrm{List} \times \mathcal{N} \times (\mathcal{N} \cup \{\Nothing\})$.
We will use the notation
$\Matchl{G}{p}{s}{i} \leadsto j$ to indicate that $(G, p, s, i, j) \in \texttt{match}_L$.
Table~\ref{tab:patterns} presents the abstract syntax of PEG patterns with lists, and Figure~\ref{fig:semgr} presents
the complete operational semantics of $\texttt{match}_L$.
If a match succeeds, the result is the position in the subject after the match,
otherwise, the result is \Nothing.
All rules are also present in the semantics of \texttt{match}, the exception being
rules $list.1$, and $list.2$, which are list-specific.

%
\begin{table}
\centering
\begin{tabular}{|c|} \hline
\chmath{.}            $\in$ Pattern  \\ %\hline
\chmath{c}            $\in$ Pattern  \\ %\hline
If $p$   $\in$ Pattern then      
  $p^*$, $!p$, $\&p$, and $\{p\}$  $\in$ Pattern \\ %\hline	
If $p_{1}$ and $p_{2}$ $\in$ Pattern then
 $p_{1}p_{2}$ and $p_{1}/p_{2}$ $\in$ Pattern \\ \hline
\end{tabular}
\caption{Syntax of PEG patterns}
\label{tab:patterns}
\end{table}
%



Rule $list.1$ deals with the successful matching of a list
element, while rule $list.2$ deals with the case of an
unsuccessful matching of a list element.
When trying to match an element of a list, the matching only
succeeds when we can match the given element completely.
If the matching of an element succeeds, the current position
in the the subject is advanced.


We can establish a direct relation between \texttt{match} and
$\texttt{match}_L$ with the help of an auxiliary function $\Mapl$,
which converts a string to a list. Given a string $s$, we have
that $\Mapl(s)$ gives us a list $l$ where the first element of
$l$ is the first character of $s$, the second element of $l$
is the second character of $s$, and so on. Then, we are going
to state the following proposition:


\begin{proposition}
\label{prop:match}
$\Matchf{G}{p}{s}{i} \leadsto j$ iff $\Matchl{G}{p}{\Mapl(s)}{i}$.
\end{proposition}

\begin{proof}
The proof is an induction on the height of the proof tree given by
\texttt{match}. As there is a straightforward relationship between the
rules of the operational semantics of \texttt{match} and the corresponding
rules in the semantics of $\texttt{match}_L$, the proof becomes trivial.
\end{proof}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Operational Semantics of PEG Patterns with Grammars and Lists %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{figure*}
{
\footnotesize
\begin{align*}
%Matching a given character
& \textbf{Matching a character} \tenspaces 
{\frac{s[i] = \chmath{c}}{\Matchl{g}{\chmath{c}}{s}{i} \leadsto \Just{i+1}}} \mylabel{ch.1} \tenspaces
{\frac{s[i] \neq \chmath{c}}{\Matchl{g}{\chmath{c}}{s}{i} \leadsto \Nothing}} \mylabel{ch.2} \\ \\
%Matching any character
& \textbf{Matching any character} \tenspaces
{\frac{i \leq |s|}{\Matchl{g}{.}{s}{i} \leadsto \Just{i+1}}} \mylabel{any.1} \tenspaces
& \tenspaces {\frac{i > |s|}{\Matchl{g}{.}{s}{i} \leadsto \Nothing}} \mylabel{any.2} \\ \\
%Not
& \textbf{Not Predicate} \tenspaces \fivespaces
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Nothing} 
	{\Matchl{g}{!p}{s}{i} \leadsto \Just{i}}} \mylabel{not.1} \tenspaces
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Just{i+j}}
	{\Matchl{g}{!p}{s}{i} \leadsto \Nothing}} \mylabel{not.2} \\ \\
%And
& \textbf{And Predicate} \tenspaces \fivespaces
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Just{i+j}}
	{\Matchl{g}{\&p}{s}{i} \leadsto \Just{i}}} \mylabel{and.1} \tenspaces
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Nothing}
	{\Matchl{g}{\&p}{s}{i} \leadsto \Nothing}} \mylabel{and.2} \\ \\
%Concatenation
& \textbf{Concatenation} \twentyspaces
{\frac{\Matchl{g}{p_{1}}{s}{i} \leadsto \Just{i+j} \interf \Matchl{g}{p_{2}}{s}{i+j} \leadsto \Just{i+j+k}}
{\Matchl{g}{p_{1}p_{2}}{s}{i} \leadsto \Just{i+j+k}}} \mylabel{con.1} \\ \\
& \fivespaces
{\frac{\Matchl{g}{p_{1}}{s}{i} \leadsto \Just{i+j} \interf \Matchl{g}{p_{2}}{s}{i+j} \leadsto \Nothing}
	{\Matchl{g}{p_{1}p_{2}}{s}{i} \leadsto \Nothing}} \mylabel{con.2} \fivespaces
{\frac{\Matchl{g}{p_{1}}{s}{i} \leadsto \Nothing}
	{\Matchl{g}{p_{1}p_{2}}{s}{i} \leadsto \Nothing}} \mylabel{con.3} \\ \\
%Ordered Choice
& \textbf{Ordered Choice} \twentyspaces
{\frac{\Matchl{g}{p_{1}}{s}{i} \leadsto \Nothing \interf \Matchl{g}{p_{2}}{s}{i} \leadsto \Nothing}
	{\Matchl{g}{p_{1}/p_{2}}{s}{i} \leadsto \Nothing}} \mylabel{ord.1} \\ \\
& \fivespaces
{\frac{\Matchl{g}{p_{1}}{s}{i} \leadsto \Just{i+j}}
	{\Matchl{g}{p_{1}/p_{2}}{s}{i} \leadsto \Just{i+j}}} \mylabel{ord.2} \tenspaces
{\frac{\Matchl{g}{p_{1}}{s}{i} \leadsto \Nothing \interf \Matchl{g}{p_{2}}{s}{i} \leadsto \Just{i+k}}
	{\Matchl{g}{p_{1}/p_{2}}{s}{i} \leadsto \Just{i+k}}} \mylabel{ord.3} \\ \\ 
%Repetition
& \textbf{Repetition} \;\;\;
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Just{i+j} \interf \Matchl{g}{p^*}{s}{i+j} \leadsto \Just{i+j+k}}
	{\Matchl{g}{p^*}{s}{i} \leadsto \Just{i+j+k}}} \mylabel{rep.1} \;\;
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Nothing}
	{\Matchl{g}{p^*}{s}{i} \leadsto \Just{i}}} \mylabel{rep.2} \\ \\
%Variable
& \textbf{Variables} \twentyspaces
{\frac{\Matchl{g}{g(A_{k})}{s}{i} \leadsto \Just{i+j}}
	{\Matchl{g}{A_{k}}{s}{i} \leadsto \Just{i+j}}} \mylabel{var.1} \tenspaces
{\frac{\Matchl{g}{g(A_{k})}{s}{i} \leadsto \Nothing}
	{\Matchl{g}{A_{k}}{s}{i} \leadsto \Nothing}} \mylabel{var.2} \\ \\
%Closed Grammars
& \textbf{Closed Grammars} \tenspaces \fivespaces
{\frac{\Matchl{g}{g(A_{k})}{s}{i} \leadsto \Just{i+j}}
	{\Matchl{g^{\prime}}{(g,A_{k})}{s}{i} \leadsto \Just{i+j}}} \mylabel{cg.1} \tenspaces
{\frac{\Matchl{g}{g(A_{k})}{s}{i} \leadsto \Nothing}
	{\Matchl{g^{\prime}}{(g,A_{k})}{s}{i} \leadsto \Nothing}} \mylabel{cg.2} \\ \\
%Lists
& \textbf{Matching a List} \tenspaces
{\frac{\Matchl{g}{p}{s[i]}{1} \leadsto |s[i]| + 1}
	{\Matchl{g}{\{p\}}{s}{i} \leadsto \Just{i+1}}} \mylabel{list.1} \tenspaces
{\frac{\Matchl{g}{p}{s[i]}{1} \neq |s[i]| + 1}
	{\Matchl{g}{\{p\}}{s}{i} \leadsto \Nothing}} \mylabel{list.2}
\end{align*}
\caption{Operational Semantics of PEGs with Lists}
\label{fig:semgr}
}
\end{figure*}


\subsection{Parsing Machine}

In LPEG, our implementation of PEGs, each PEG pattern translates to a program,
which executes on a virtual parsing machine. The parsing machine has a state,
which changes according to the instructions of a program.

The machine has a program counter that addresses the next instruction to be executed,
a register that holds the current subject, a register that holds the current position
in the subject, and a stack that the machine uses for pushing return addresses, list
entries, and backtrack entries. A return address is just a new value for the program counter,
a list entry holds a subject and a position, and a backtrack entry holds an address, the subject
and a position in the subject. The machine has the following basic instructions, where the
instructions \texttt{Open} and \texttt{Close} were added in order to deal with lists:

\texttt{Char} \textbf{x}: tries to match the character \emph{x}
against the current subject position, advancing one position if successful.

\texttt{Any}: advances one position if the end of the subject was not
reached; it fails otherwise.

\texttt{Choice} \textbf{l}: pushes a backtrack entry on the stack,
where \textit{l} is the offset of the alternative instruction.

\texttt{Jump} \textbf{l}: relative jump to the instruction at offset \textit{l}.

\texttt{Call} \textbf{l}: pushes the address of the next instruction in the stack,
and jumps to the instruction at offset \textit{l}.

\texttt{Return}: pops an address from the stack and jumps to it.

\texttt{Commit} \textbf{l}: commits to a choice, popping the top entry
from the stack, throwing it away, and jumping to the instruction at offset \textit{l}.

\texttt{Fail}: forces a failure. When any failure occurs, the machine
pops the stack until it finds a backtrack entry, then uses that entry plus the
stack as the new machine state.

\texttt{Open}: changes the current subject and position, pushing on the stack
the previous values. The new current position is the beginning of the new
current subject.

\texttt{Close}: if the current position points to the end of the current subject,
this instruction pops the top entry from the stack, restoring the previous values
for the position and the subject. If the current position does not point to the
end of the subject, a failure occurs. Otherwise, the position in the subject is advanced.

Figure~\ref{fig:semantics} presents the operational semantics of the parsing
machine as a relation between machine states. The program $\mathcal{P}$ that the
machine is executing is implicit. The state
is either a tuple $\mathcal{N} \times \mathrm{List} \times \mathcal{N} \times \mathrm{Stack}$,
containing the next instruction to execute (\emph{pc}), the current subject (\emph{s}),
the current position in the subject (\emph{i}), and a stack (\emph{e}), or $\Sfail{e}$,
a failure state with stack \emph{e}. Stacks are lists of
$(\mathcal{N} \times \mathrm{List} \times \mathcal{N}) \cup (\mathrm{List} \times \mathcal{N})
\cup \mathcal{N}$, where a stack position of form $\mathcal{N} \times \mathrm{List} \times \mathcal{N}$
represents a backtrack entry, a stack position of form $\mathrm{List} \times \mathcal{N}$ represents
a list entry, and a stack position of form $\mathcal{N}$ represents a return address.

The relation $\xrightarrow{\mathrm{Instruction}}$ relates two states when the instruction
addressed by \emph{pc} in the antecedent state matches the label, and the guard (if present)
is valid.
%The transitive closure of this relation is an execution of the machine. 
%
\begin{figure*}
{
\footnotesize
\[
\begin{array}{rlll}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{Char}{x}}%
      {\Sstate{pc+1}{s}{i+1}{e}}{\Subi=x}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{Char}{x}}%
      {\Sfail{e}}{\Subi\not=x}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{Any}{}}%
      {\Sstate{pc+1}{s}{i+1}{e}}{i+1 \leq |\Sub|}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{Any}{}}%
      {\Sfail{e}}{i+1 > |\Sub|}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{Choice}{l}}%
      {\Sstate{pc+1}{s}{i}{(pc+l,s,i):e}}{}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{Jump}{l}}%
      {\Sstate{pc+l}{s}{i}{e}}{}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{Call}{l}}%
      {\Sstate{pc+l}{s}{i}{(pc+1):e}}{}
\Sstep{\Sstate{pc_0}{s}{i}{pc_1:e}}{\Ia{Return}{}}%
      {\Sstate{pc_1}{s}{i}{e}}{}
\Sstep{\Sstate{pc}{s}{i}{h:e}}{\Ia{Commit}{l}}%
      {\Sstate{pc+l}{s}{i}{e}}{}
\Sstep{\Sstate{pc}{s}{i}{(pc_1,s_1,i_1):e}}{\Ia{PartialCommit}{l}}%
      {\Sstate{pc+l}{s}{i}{(pc_1,s_1,i):e}}{}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{Fail}{}}%
      {\Sfail{e}}{}
\Sstep{\Sfail{pc:e}}{\mbox{\emph{any}}}%
      {\Sfail{e}}{}
\Sstep{\Sfail{(s,i):e}}{\mbox{\emph{any}}}%
      {\Sfail{e}}{}
\Sstep{\Sfail{(pc,s,i):e}}{\mbox{\emph{any}}}%
      {\Sstate{pc}{s}{i}{e}}{}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{Open}{}}%
      {\Sstate{pc+1}{\Subi}{1}{(s,i):e}}{}
\Sstep{\Sstate{pc}{s}{i}{(s_1,i_1):e}}{\Ia{Close}{}}%
      {\Sstate{pc+1}{s_1}{i_1+1}{e}}{i=|\Sub[i_1]|+1}
\Sstep{\Sstate{pc}{s}{i}{(s_1,i_1):e}}{\Ia{Close}{}}%
      {\Sfail{e}}{i\neq|\Sub[i_1]|+1}
\end{array}
\]
}
\caption{Operational Semantics of the Parsing Machine}
\label{fig:semantics}
\end{figure*}



\section{Transforming Patterns to Programs}
\label{sec:equivalence}

The process of translating a pattern into a program is bottom up, and done at runtime.
The simplest patterns are translated to simple programs, and then
programs are combined according to rules specific for each PEG operation.
Programs are opaque entities for the translation process, the pattern
that originated them is not important, as long as the programs are
valid. In our implementation the process is fully incremental, and combining
programs is a simple matter of concatenating their texts.

In~\cite{dls:lpeg}, we represent this compilation process
using a transformation function $\mathrm{\Pi}$, which operates
on the domain $\mathrm{Grammar} \times \mathcal{N} \times \mathrm{Pattern}$,
where $\Pi(g,i,p)$ is the translation of pattern $p$ in the
context of grammar $g$ and with position $i$ relative to the
beginning of the closed grammar which contains it (if the pattern
is not part of a closed grammar then the value can be arbitrary).
We will also use the notation $|\Pi(g,i,p)|$, which
means the number of instructions of the program $\Pi(g,i,p)$.

The correctness of this transformation has already been proved
for the \texttt{match} relation. As this transformation
remains the same after the addition of lists, and we have
already proved Proposition~\ref{prop:match}, we just need
to prove the extra cases corresponding to rules $list.1$
and $list.2$ to prove that this transformation is also correct
for $\texttt{match}_L$.

Given a PEG grammar $g$, a position $i$ relative to the beginning of the grammar,
and a pattern $\{p\}$, we have the following transformation from pattern to the
virtual machine instructions:
%
\begin{equation*}
\begin{split}
\Pi(g, i, \{p\}) \equiv \;
	&{\tt Open} \\
	&\Pi(g, i+1, p)\\
	&{\tt Close}
\end{split}
\end{equation*}
%
The transformation for a list pattern $\{p\}$ just puts a pair of instructions \texttt{Open-Close}
around the pattern $p$.

The proof is an induction on the height of the proof tree given by the semantics of $\texttt{match}_L$.
What we are going to prove first is:
%
\begin{equation*}
\begin{split}
&\texttt{If } \Matchl{g}{\{p\}}{s}{i} = \Just{i+1} \texttt{ then}\\
&\Sstepp{\Sstate{pc}{s}{i}{e}}{\Pi(g,i,\{p\})}
	{\Sstate{pc + |\Pi(g,i,p)| + 2}{s}{i+1}{e}}{}
\end{split}
\end{equation*}
%
This case is related to the semantic rule $list.1$,
where the matching of element $i$ of a list
was successful and matched the element entirely.
We have the following sequence of transitions:
%
\begin{align*}
\xrightarrow{Open} \; &
	{\Sstate{pc + 1}{s[i]}{1}{(s, i):e}} \\
\xrightarrow{\Pi(g, i+1, p)} \; &
	{\Sstate{pc + |\Pi(g,i,p)| + 1}{s[i]}{|s[i]|+1}{(s, i):e}} \\
\xrightarrow{Close} \; &
	{\Sstate{pc + |\Pi(g,i,p)| + 2}{s}{i+1}{e}}
\end{align*}
%
After the \texttt{Open} instruction, the subject becomes
$s[i]$, and the current position is $1$. By induction
we know the execution of $\Pi(g, i+1, p)$ leads to
$\Sstate{pc + |\Pi(g,i,p)| + 1}{s[i]}{|s[i]|+1}{(s, i):e}$,
and after the \texttt{Close} instruction we reach the final
state $\Sstate{pc + |\Pi(g,i,p)| + 2}{s}{i+1}{e}$.


We also need to prove that:
%
\begin{equation*}
\begin{split}
&\texttt{If } \Matchl{g}{\{p\}}{s}{i} = \Nothing \texttt{ then}\\
&\Sstepp{\Sstate{pc}{s}{i}{e}}{\Pi(g,i,\{p\})}
	{\Sfail{e}}{}
\end{split}
\end{equation*}
%
This case is related to the semantic rule $list.2$,
where the matching of element $i$ of a list
failed or did not match the element entirely.
Considering $n^\prime < |s[i]|+1$,  if the
matching of $p$ succeeds and results in $n^\prime$,
we have the following sequence of transitions:
%
\begin{align*}
\xrightarrow{Open} \; &
	{\Sstate{pc + 1}{s[i]}{1}{(s, i):e}} \\
\xrightarrow{\Pi(g, i+1, p)} \; &
	{\Sstate{pc + |\Pi(g,i,p)| + 1}{s[i]}{n^\prime}{(s, i):e}} \\
\xrightarrow{Close} \; &
	{\Sfail{e}}{}
\end{align*}
%
As $n^\prime < |s[i]|+1$ the execution of the \texttt{Close}
instruction leads the machine to a failure state.

There is also the case where the matching of $p$ fails, leading
the machine to a failure state $\Sfail{e}$ too.


\section{Optimizations}
\label{sec:optimizations}

The previous section showed how to compile list patterns to our parsing machine, and proved the
correctness of this compilation. In several cases, though, the compilation could be more efficient,
avoiding unecessary pushs and pops on the machine's stack. This section shows another way
to compile some list patterns by using a few extra instructions that we will define, generating
more efficient programs.

Figure~\ref{fig:optimizations} shows the instructions we are adding to the machine and their
semantics. Let's start with a very common pattern, $\{ c_{1} \ldots c_{n} \}$, that is, a pattern that
matches a list of $n$ characters. The current program for this pattern is an \texttt{Open} instruction
followed by a sequence of \texttt{Char} instructions and a \texttt{Close} instruction. We can now
compile this pattern to a single \texttt{String} instruction with the string ``$c_{1} \ldots c_{2}$'' as its 
argument.

%
\begin{figure*}
{\footnotesize
\[
\begin{array}{rlll}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{String}{x}}%
      {\Sstate{pc+1}{s}{i+1}{e}}{s[i] = \Mapl(x)}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{String}{x}}%
      {\Sfail{e}}{s[i] \neq \Mapl(x)}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Iaa{TestString}{l}{x}}%
      {\Sstate{pc+1}{s}{i+1}{e}}{s[i] = \Mapl(x)}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Iaa{TestString}{l}{x}}%
      {\Sstate{pc+l}{s}{i}{e}}{s[i] \neq \Mapl(x)}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{NotAny}{}}%
      {\Sstate{pc+1}{s}{i}{e}}{i = |s|+1}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{NotAny}{}}%
      {\Sfail{e}}{i \neq |s|+1}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{ChoiceOpen}{l}}%
      {\Sstate{pc+1}{\Subi}{1}{(pc+l,s,i):e}}{}
%\Sstep{\Sstate{pc}{s}{i}{(pc_1,s_1,i_1):e}}{\Ia{CloseCommit}{l}}%
%      {\Sstate{pc+l}{s_1}{i_1+1}{e}}{i=|\Sub[i_1]|+1}
%\Sstep{\Sstate{pc}{s}{i}{(pc_1,s_1,i_1):e}}{\Ia{CloseCommit}{l}}%
%      {\Sstate{pc_1}{s_1}{i_1}{e}}{i\neq|\Sub[i_1]|+1}
\Sstep{\Sstate{pc}{s}{i}{(pc_1,s_1,i_1):e}}{\Ia{PartialCloseCommit}{l}}%
      {\Sstate{pc+l}{s_1[i_1+1]}{1}{(pc_1,s_1,i_1+1):e}}{i=|\Sub[i_1]|+1}
\Sstep{\Sstate{pc}{s}{i}{(pc_1,s_1,i_1):e}}{\Ia{PartialCloseCommit}{l}}%
      {\Sstate{pc+l}{s_1}{i_1}{e}}{i\neq|\Sub[i_1]|+1}
\end{array}
\]
}
\caption{Operational Semantics of Specialized Instructions for Lists}
\label{fig:optimization}
\end{figure*}


%Another common pattern we can optimize is $\{ p_{1} \} / p_{2}$. The current program for this pattern
%has a \texttt{Open} instruction immediately following a \texttt{Choice} instruction, both pushing the
%same subject and position on the stack. We can combine these two instructions if we also combine the
%consecutive \texttt{Close} and \texttt{Commit} instructions, having this program:

% program ChoiceOpen l1 / p1 / CloseCommit l2 / p2

%Consider what happens when $p_{1}$ fails and $p_{2}$ succeeds:

% transition for case where p1 fails and p2 succeeds

%As you can see, the machine ends up in the same state as in the original program.

A related optimization is for the pattern $\{ p \}^*$. In \cite{dls:lpeg} the related pattern $p^*$ compiles
to a program starting with a \texttt{Choice} instruction followed by the compilation of $p$ and a \texttt{PartialCommit}
instruction, which updates the top of the stack. When compiling $\{ p \}^*$ we will have an \texttt{Open} following
a \texttt{Choice} instruction, and we can combine them in a \texttt{ChoiceOpen} instruction if we combine the ending
\texttt{Close} and \texttt{PartialCommit} instructions in a single \texttt{PartialCloseCommit} instruction, which
updates the stack and changes the subject and the current position. Below is the sequence of transitions when $\{ p \}^*$
matches subject $s$ at position $i$, advancing to position $i+j$:
%
% transitions for case where {p}* matches advancing to i+j
%
\begin{align*}
\xrightarrow{ChoiceOpen} \; &
	{\Sstate{pc + 1}{s[i]}{1}{(pc + |\Pi(g,x,p)| + 2, s,i):e}} \\
\xrightarrow{\Pi(g,x+1,p)} \; &
	{\Sstate{pc + |\Pi(g,x,p)| + 1}{s}{i + j}{(pc + |\Pi(g,x,p)| + 2, s,i):e}} \\
\xrightarrow{PartialCloseCommit} \; &
	{\Sstate{pc + 1}{s[i+1]}{1}{(pc + |\Pi(p)| + 2, s,i + 1):e}}  \\
\xrightarrow{\Pi(g,x+|\Pi(g,x,p)|+2,\{p\}^*)} \; &
	{\Sstate{pc + |\Pi(g,x,\{p\}^*)|}{s}{i + j}{e}}
\end{align*}
%
Notice that \texttt{PartialCloseCommit} has to change the current subject.

Another optimization we can do is related to \emph{head fail}s. A head fail occurrs when the matching
of a pattern fails right in the beginning of a subject. This kind of failure is very common when we
have a pattern like $\{ c_{1} \ldots c_{n} \}$. Therefore, when matching a pattern like
$\{ c_{1} \ldots c_{n} \} p_1 / p_2$, it is somewhat expensive to push a backtrack entry that will be
most of the time discarded when trying to match character $c_{1}$. To avoid the cost of pushing this
entry and discarding it just after, we will use the \texttt{TestString} instruction, which is similar to
\texttt{String}, but also receives a label to jump in case of a failure. Now, we have the following transformation:
%
\begin{equation*}
\begin{split}
\Pi(g,x, \{c_{1} \ldots c_{n} \} p_1 / p_{2}) \equiv \;
	&{\tt TestString} \; |\Pi(g,x,p_{1})| + 3 \;\; c_1 \ldots c_n  \\
	&{\tt Choice} \; |\Pi(g,x,p_{1})| + 2 \;\;\; 1\\
	&\Pi(g,x+2,p_{1})\\
	&{\tt Commit } \; |\Pi(g,x,p_{2})| + 1\\
	&\Pi(g,x+|\Pi(g,x,p_1)|+3,p_{2})
\end{split}
\end{equation*}
%
Notice that now the \texttt{Choice} instruction needs an offset, now
when pushing a backtrack entry, this instruction saves the current
subject position minus a given offset. All the previous use of
\texttt{Choice} have an offset of zero. We will omit this offset
when its value is zero.

In case of an unsuccessful matching of $\{c_1 \ldots c_n\}$ and a successful
matching of $p_2$, we have the following sequence of transitions:
\begin{align*}
\xrightarrow{TestString} &
	{\Sstate{pc + |\Pi(g,x,p_{1})| + 3}{s}{i}{e}} \\
\xrightarrow{\Pi(g,x+|\Pi(g,x,p_1)|+3,p_{2})} &
    {\Sstate{pc + |\Pi(g,x, \{c_1 \dots c_n \} p_1 / p_2)|}{s}{i+k}{e}}
\end{align*}

Finally, there is an optimization related to the ordered choice of lists which
involves the creation of a new instruction for the machine and also requires some
pattern transformation. If we have a pattern like $\{p_1\} / \{p_2\}$, and $p_1$ fails,
we need first to restore the subject and the position, and right after we need to
change them again to try the matching of $p_2$. As an \texttt{Open} instruction is
expensive, it is more efficient to generate code for an equivalent pattern, which
does less changes in the subject.

A first tought would be translate $\{p_1\} / \{p_2\}$ to $\{ p_1 / p_2 \}$. When $p_1$
fails, both pattern are equivalents. But if there is an intersection between the subjects
reconized by $p_1$, and those reconized by $p_2$, then the patterns are not equivalent
when $p_1$ succeeds. In such situation, if $p_1$ and $p_2$ succeed when matching a subject
$s$, where $p_2$ matches the whole subject, while $p_1$ does not, we have pattern
$\{p_1\} / \{p_2\}$ will succeed, while pattern $\{ p_1 / p_2 \}$ will fail.

To deal with this situation, instead of matching just $p_1$, we need to match $p_1 !.$.
Doing this way, we guarantee that if $p_1$ does not match the subject entirely, we
always try to match $p_2$. Instead of doing an usual transformation for the pattern
$!.$, we will create a specific instruction \texttt{NotAny}, which executes faster
than the trivial code. The transformation is given below:
%
\begin{equation*}
\begin{split}
\Pi(g, x, \{ p_1 !. / p_2\}) \equiv \;
	&{\tt Open} \;  \\
	&{\tt Choice} \; |\Pi(g,x,p_1)| + 3 \\
	&\Pi(g, x+2, p_1)\\
	&{\tt NotAny } \; \\
	&{\tt Commit } \; |\Pi(g,x,p_2)| + 1\\
	&\Pi(g, x + |\Pi(g,x,p_1)| + 4, p_2) \\
	&{\tt Close} \; 
\end{split}
\end{equation*}
%
In case of $p_1$ succeeding, without matching the whole input, and $p_2$
succeeding, matching the whole input, we have the following sequence of
transitions, where $n^\prime < |s[i]| + 1$:
%
\begin{align*}
\xrightarrow{Open} \; &
	{\Sstate{pc + 1}{s[i]}{1}{(s,i):e}} \\
\xrightarrow{Choice} \; &
	{\Sstate{pc + 2}{s[i]}{1}{(pc + |\Pi(g,x,p_1)| + 3, s[i], 1):(s,i):e}} \\
\xrightarrow{\Pi(g,x+2,p_1)} \; &
	{\Sstate{pc + |\Pi(g,x,p_1)| + 2}{s[i]}{n^\prime}{(pc + |\Pi(g,x,p_1)| + 3, s[i], 1):(s,i):e}} \\
\xrightarrow{NotAny} \; &
	{\Sfail{(pc + |\Pi(g,x,p_1)| + 3, s[i], 1):(s,i):e}} \\
\xrightarrow{Fail} \; &
	{\Sstate{pc + |\Pi(g,x,p_1)| + 3}{s[i]}{1}{(s,i):e}} \\
\xrightarrow{\Pi(g,x+|\Pi(g,x,p_1)|+4, p_2)} \; &
	{\Sstate{pc + |\Pi(g, x, \{ p_1 !. / p_2 \})|-1, p_2)}{s[i]}{|s[i]|+1}{(s,i):e}} \\
\xrightarrow{Close} \; &
	{\Sstate{pc + |\Pi(g, x, \{ p_1 !. / p_2 \})|)}{s}{i+1}{e}}
\end{align*}
%



% optimization benchmarks

\section{Captures}
\label{sec:captures}

In LPEG, a capture is a mix of conventional captures with semantic
actions. In order to add captures, we need to change the $\texttt{match}_L$
relation, which now becomes:
$\mathrm{Grammar} \times \mathrm{Pattern} \times \mathrm{List} \times \mathcal{N} \times ((\mathcal{N}, Capture^*) \cup \{\Nothing\})$,
where $Capture^*$ represents a list of captures.
We will use the notation
$\Matchl{G}{p}{s}{i} \leadsto j$ to indicate that $(G, p, s, i, j) \in \texttt{match}_L$.

The use of captures does not affect the matching of a subject, if a matching was successful without the
use of captures, it still be successful if we do it again using captures. Therefore, the use of captures
will only affect the list of captures.

Table~\ref{tab:captures} lists the capture patterns. We have four kinds of captures:
\emph{simple}, which captures a given portion of the subject; \emph{constant},
which creates a constant capture; \emph{function}, which calls a given function
with a list of captures; and \emph{fold}, which gives to a function a list of
captures, where the given function will fold the captures, producing a single value.
%
\begin{table}
\centering
\begin{tabular}{|c|} \hline
If $v$ $\in$ Value then $\Pcap{const}{v}$ $\in$ Pattern  \\ %\hline
If $p$ $\in$ Pattern then $\Pcap{simp}{p}$ $\in$ Pattern  \\ %\hline
If $p$ $\in$ Pattern and $f$ $\in$ $Value^* \rightarrow Value^*$ then $\Pcap{func}{f}$ $\in$ Pattern \\ %\hline
If $p$ $\in$ Pattern and $f$ $\in$ $Value \rightarrow Value \rightarrow Value$ then $\Pcap{fold}{f}$ $\in$ Pattern \\ \hline
\end{tabular}
\caption{Definition of Capture Patterns}
\label{tab:captures}
\end{table}
%
Figure~\ref{fig:captures} presents the operational semantics of $\texttt{match}_L$ when dealing with these patterns,
plus the new semantics of the concatenation pattern. The
semantics of the other PEG patterns is quite the same, the only difference is that the result of a successful matching
is now a pair $(\mathcal{N}, Capture^*)$. From now on the successful concatenation of two patterns also appends the
list of captures made by the second pattern on the list of captures made by the first pattern.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Operational Semantics of PEG with Captures %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{figure*}[t]
{
\footnotesize
\begin{align*}
%Concatenation
& \textbf{Concatenation} \twentyspaces
{\frac{\Matchl{g}{p_{1}}{s}{i} \leadsto \Just{i+j}{c_1} \interf \Matchl{g}{p_{2}}{s}{i+j} \leadsto \Just{(i+j+k, $c_2$)}}
	{\Matchl{g}{p_{1}p_{2}}{s}{i} \leadsto \Just{i+j+k}{c_1 ++ c_2}}} \mylabel{con.1} \\ \\
&
{\frac{\Matchl{g}{p_{1}}{s}{i} \leadsto \Justc{i+j}{c_1} \interf \Matchl{g}{p_{2}}{s}{i+j} \leadsto \Nothing}
	{\Matchl{g}{p_{1}p_{2}}{s}{i} \leadsto \Nothing}} \mylabel{con.2} \fivespaces
{\frac{\Matchl{g}{p_{1}}{s}{i} \leadsto \Nothing}
	{\Matchl{g}{p_{1}p_{2}}{s}{i} \leadsto \Nothing}} \mylabel{con.3} \\ \\
%Matching a Constant Capture
& \textbf{Matching a Constant Capture} \tenspaces 
{\frac{}
	{\Matchl{g}{\Pcap{const}{v}}{s}{i} \leadsto \Justc{i}{\{\Pcap{Const}{v}\}}}} \mylabel{const.1} \\ \\
%Matching a Simple Capture
& \textbf{Matching a Simple Capture} \tenspaces
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Nothing}
	{\Matchl{g}{\Pcap{simp}{p}}{s}{i} \leadsto \Nothing}} \mylabel{simple.2} \\ \\
& \tenspaces
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Justc{i+j}{c}}
	{\Matchl{g}{\Pcap{simp}{p}}{s}{i} \leadsto \Justc{i+j}{(\Pcapp{Simple}{s}{i}):c ++ \{\Pcap{Close}{j}\}}}} \mylabel{simple.1} \\ \\
%Matching a Function Capture
& \textbf{Matching a Function Capture} \tenspaces
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Nothing}
	{\Matchl{g}{\Pcap{func}{f}}{s}{i} \leadsto \Nothing}} \mylabel{func.2} \\ \\
& \tenspaces
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Justc{i+j}{c}}
	{\Matchl{g}{\Pcap{func}{f}}{s}{i} \leadsto \Justc{i+j}{\Pcap{Func}{f}:c ++ \{\Pcap{Close}{0}\}}}} \mylabel{func.1} \\ \\
%Matching a Fold Capture
& \textbf{Matching a Fold Capture} \tenspaces
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Nothing}{\Matchl{g}{\Pcap{fold}{f}}{s}{i} \leadsto \Nothing}} \mylabel{fold.2} \\ \\
& \tenspaces
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Justc{i+j}{c}}{\Matchl{g}
	{\Pcap{fold}{f}}{s}{i} \leadsto \Justc{i+j}{\Pcap{Fold}{f}:c ++ \{\Pcap{Close}{0}\}}}} \mylabel{fold.1}
\end{align*}
\caption{Operational Semantics of PEG Patterns related to Captures}
\label{fig:captures}
}
\end{figure*}

Accordingly, we also need to change the state of the parsing machine and to add new instructions
to deal with captures. The state of our machine is now either a tuple
$\mathcal{N} \times \mathrm{List} \times \mathcal{N} \times \mathrm{Stack} \times \mathrm{Capture^*}$,
where we will use a symbol \emph{k} to denote the list of captures, or $\Sfail{e}$.
Now, a backtrack entry keeps also a list of captures.

The new instructions of the parsing machine are: \texttt{ConstCap}, which pushes a value on the list
of captures; \texttt{SimpCap}, which indicates the beginning of a simple capture; \texttt{CloseCap},
which indicates the ending of a capture; \texttt{FuncCap}, which pushes a function capture
on the list of captures; and \texttt{FoldCap}, which pushes a fold capture on the list of captures.
Figure~\ref{fig:semcaptures} presents the semantics of these new instructions. The figure also presents
the new semantics of some instructions as \texttt{Choice} and \texttt{Fail}, and shows the transitions
related to the failure state.
%
\begin{figure*}
{
\footnotesize
\[
\begin{array}{rlll}
\Sstep{\Sstatec{pc}{s}{i}{e}{k}}{\Ia{Choice}{l}}%
      {\Sstatec{pc+1}{s}{i}{(pc+l,s,i,k):e}{k}}{}
\Sstep{\Sstatec{pc}{s}{i}{(pc_1,s_1,i_1,k_1):e}{k}}{\Ia{PartialCommit}{l}}%
      {\Sstatec{pc+l}{s}{i}{(pc_1,s_1,i,k):e}{k}}{}
\Sstep{\Sstatec{pc}{s}{i}{e}{k}}{\Ia{Fail}{}}%
      {\Sfail{e}}{}
\Sstep{\Sfail{(pc,s,i,k):e}}{\mbox{\emph{any}}}%
      {\Sstatec{pc}{s}{i}{e}{k}}{}
\Sstep{\Sstatec{pc}{s}{i}{e}{k}}{\Ia{ConstCap}{v}}%
      {\Sstatec{pc+1}{s}{i}{e}{\Pcap{Const}{v}:k}}{}
\Sstep{\Sstatec{pc}{s}{i}{e}{k}}{\Ia{SimpleCap}{p}}%
      {\Sstatec{pc+1}{s}{i}{e}{\Pcapp{Simple}{s}{i}:k}}{}
\Sstep{\Sstatec{pc}{s}{i}{e}{k}}{\Ia{FuncCap}{v}}%
      {\Sstatec{pc+1}{s}{i}{e}{\Pcap{Func}{f}:k}}{}
\Sstep{\Sstatec{pc}{s}{i}{e}{k}}{\Ia{FoldCap}{v}}%
      {\Sstatec{pc+1}{s}{i}{e}{\Pcap{Fold}{f}:k}}{}
\end{array}
\]
}
\caption{Operational Semantics of the Parsing Machine using Captures}
\label{fig:semcaptures}
\end{figure*}


\subsection{Evaluating the List of Captures}

After the matching, the list of captures is evaluated, in order to produce
the actual values.  In case of a constant capture, the final value is already on the list of
captures. In case of a simple capture, the final value is the slice from $i$ until $j-1$ of the subject
$s$. In case of a function capture, the function $f$ is called and receive as its parameters the values
produced by a list of captures. The values returned by $f$ are the final values of that list of captures.

In case of a fold capture, the $f$ function will be called with the values produced by a list of captures.
If \texttt{eval} of a list of captures produces values $v_1, v_2, \ldots, v_n$, we have that
$fold f v_1, v_2, \ldots, v_n$ will produce the value: $f(\ldots f(f(v_1,v_2), v_3) \ldots,v_n)$.
If the list of values has just one value, then the result of $fold f v_1$ is $v_1$. If the list
is empty, the result is unspecified.

The \texttt{eval} function and its auxiliary functions do this job. The definition of \texttt{eval} is:
$\mathrm{State} \times \mathrm{State}$, where $State$ is a pair $(\mathrm{Capture^*}, \mathrm{Value^*})$, where
$Capture^*$ is a list of captures and $Value$ a list of values.

Functions \texttt{esimp}, \texttt{efunc}, and \texttt{efold} are similar to \texttt{eval}, but get also an
extra state. In case of \texttt{esimp}, the extra state is a tuple $(\mathrm{Subject}, \mathcal{N}, \mathrm{Capture^*})$.
In case of \texttt{efunc} and \texttt{efold}, the extra state is a tuple $(\mathrm{Function}, \mathrm{Capture^*})$.
In all tuples, $Capture^*$ is the list of captures until the beginning of the corresponding capture.

After applying \texttt{eval} to the list of captures constructed by $\mathrm{match}_L$ and an empty list of values,
the result is an empty list of captures and a list of values obtained from the captures.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Operational Semantics of eval %%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure*}[t]
{
\footnotesize
\begin{align*}
%Not
& %\textbf{eval} \tenspaces
{\frac{}
	{\Eval{(\Emptyl,v)} = (\Emptyl,v)}}  \mylabel{eval.1} \tenspaces 
{\frac{}
	{\Eval{(\Pcap{Close}{j}:cs, vs)} = (\Pcap{Close}{j}:cs, vs)}} \mylabel{eval.2} \\ \\
%
& {\frac{\Eval{(cs, vs ++ \{v\})} = (cs_1, vs_1)}
	{\Eval{(\Pcap{Const}{v}:cs, vs)} = (cs_1, vs_1)}} \mylabel{eval.3} \tenspaces
{\frac{\Esimple{(s,i,vs)}{(cs, \Emptyl)} = (cs_1, vs_1)}
	{\Eval{(\Pcap{Simp}{s}{i}:cs, vs)} = (cs_1, vs_1)}} \mylabel{eval.4} \\ \\
%
& {\frac{\Efunction{(f,vs)}{(cs, \Emptyl)} = (cs_1, vs_1)}
	{\Eval{(\Pcap{Func}{f}:cs, vs)} = (cs_1, vs_1)}} \mylabel{eval.5} \tenspaces
{\frac{\Efold{(f,vs)}{(cs, \Emptyl)} = (cs_1, vs_1)}
	{\Eval{(\Pcap{Fold}{f}:cs, vs)} = (cs_1, vs_1)}} \mylabel{eval.6} \\ \\
%
& %\textbf{evsimple} \tenspaces 
{\frac{\Eval{(cs, vs)} = (cs_2, vs_2)}
	{\Esimple{(s,i,vs_1)}{(\Pcap{Close}{j}:cs, vs)} = (cs_2, vs_1 ++ (sub(s, i, j)):vs_2)}} \mylabel{esimp.1} \\ \\
& {\frac{\Eval{(c:cs, \Emptyl)} = (\Pcap{Close}{j}:cs_2, vs_2) \;\;\; \Esimple{(s,i,vs_1)}{(\Pcap{Close}{j}:cs_2,vs_2)} = (cs_3, vs_3)}
	{\Esimple{(s,i,vs_1)}{(c:cs, vs)} = (cs_3, vs_3)}}  \, ,c \neq (\Pcap{Close}{j}) \mylabel{esimp.2} \\ \\
%
& %\textbf{evfunc} \tenspaces 
{\frac{\Eval{(cs, \Emptyl)} = (cs_2, vs_2)}
	{\Efunction{(f,vs_1)}{(\Pcap{Close}{j}:cs, vs)} = (cs_2, vs_1 ++ \{f (vs)\} ++ vs_2)}} \mylabel{efunc.1} \\ \\
& {\frac{\Eval{(c:cs, \Emptyl)} = (\Pcap{Close}{j}:cs_2, vs_2) \;\;\; \Efunction{(f,vs_1)}{(\Pcap{Close}{j}):cs_2),vs_2)} = (cs_3, vs_3)}
	{\Efunction{(f,vs_1)}{(c:cs, vs)} = (cs_3, vs_3)}}  \; ,\,c \neq \Pcap{Close}{j} \mylabel{efunc.2} \\ \\
%
& %\textbf{evfold} \tenspaces 
{\frac{\Eval{(cs, \Emptyl)} = (cs_2, vs_2)}
	{\Efold{(f,vs_1)}{(\Pcap{Close}{j}:cs, vs)} = (cs_2, vs_1 ++ (fold (f, vs)):vs_2)}} \mylabel{efold.1} \\ \\
& {\frac{\Eval{(c:cs, \Emptyl)} = (\Pcap{Close}{j}:cs_2, vs_2) \;\;\; \Efunction{(f,vs_1)}{(\Pcap{Close}{j}:cs_2),vs_2)} = (cs_3, vs_3)}
	{\Efold{(f,vs_1)}{(c:cs, vs)} = (cs_3, vs_3)}}  \; ,\,c \neq \Pcap{Close}{j}) \mylabel{efold.2}
\end{align*}
}
\caption{Operational Semantics of \texttt{eval}, \texttt{esimp}, \texttt{efunc}, and \texttt{efold}}
\label{fig:eval}
\end{figure*}




\section{Related Work}
\label{sec:related}


\section{Conclusions}
\label{sec:conclusions}

Based on the work of ~\cite{warth:ometa}, we have presented an extension of PEGs which
allows the matching of lists, instead of just characters. According, we have also extended
the definition of our virtual parsing machine for PEGs, and we have proved the transformation
from extended PEG patterns to programs in our parsing machine is correct.

We also added new list-specific instructions to the parsing machine, in order to improve its
performance when dealing with lists.

To perform semantic actions, we extended the semantics of the $\mathrm{match}_L$ relation, adding
new patterns related to the capture of values. During the matching, our machine does not perform
semantic actions, it only gathers enough information about the captures so that after the matching
it can produce the corresponding values.

We have shown the implementation of our parsing machine for PEGs and its list extension is really fast.
When compared with OMeta, which also implements an extension of PEGs which supports the matching of lists,
the performance of LPEG is almost $10$ times better. We have also a prototypal implementation of a
Just-In-Time (JIT) compiler for LPEG. By using the JIT we can, in general, improve the performance of a
parsing machine's program without captures by a factor of approximately $3$.

\bibliographystyle{sbc}
\bibliography{sblp} 


\end{document}
