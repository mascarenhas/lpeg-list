\documentclass[12pt]{article}

\usepackage{sbc-template}

\usepackage{graphicx,url}

%\usepackage[brazil]{babel}   
\usepackage[latin1]{inputenc}  
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{alltt}


\newcommand{\Pow}{\, \widehat{} \,\,}
\newcommand{\Match}[3]{\mathrm{match} \;\, #1\;#2\;#3}
\newcommand{\Matchf}[4]{\mathrm{match} \;\, #1\;#2\;#3\;#4}
\newcommand{\Matchl}[4]{\mathrm{match}_L \;\, #1\;#2\;#3\;#4}
\newcommand{\Matchlk}[5]{\mathrm{match}_L \;\, #1\;#2\;#3\;#4\;#5}
\newcommand{\Matchrec}[5]{\mathrm{match} \;\, #1\;#2\;#3\;#4\;#5}
\newcommand{\Nothing}{{\tt fail}}
\newcommand{\Just}[1]{\mbox{#1}}
\newcommand{\Justc}[2]{(\mbox{#1},\,#2)}
\newcommand{\Striple}[3]{(#1,\,#2,\,#3)}
\newcommand{\Sstate}[4]{\langle#1,\,#2,\,#3,\,#4\rangle}
\newcommand{\Sstatec}[5]{\langle#1,\,#2,\,#3,\,#4,\,#5\rangle}
\newcommand{\Sfail}[1]{\mbox{\bf Fail}{\langle#1\rangle}}
\newcommand{\Sstep}[4]{#1 & \xrightarrow{#2} & #3 & #4\\}
\newcommand{\Sstepp}[4]{#1 \xrightarrow{#2} #3\\}
\newcommand{\Ia}[2]{\mbox{{\scriptsize {\tt #1} $#2$}}}
\newcommand{\Iaa}[3]{\mbox{{\scriptsize {\tt #1} $#2$ $#3$}}}
\newcommand{\Fail}{\mbox{\bf Fail}}
\newcommand{\Hd}[1]{\mbox{hd}(#1)}
\newcommand{\Sub}{{s}}
\newcommand{\Subb}{{s_1}}
\newcommand{\Subi}{\Sub [i]}
\newcommand{\Subbi}{\Subb [i]}
\newcommand{\MathN}[1]{\mbox{\emph{#1}}}
\newcommand{\Nat}{\mbox{\bf N}}
\newcommand{\myarrow}{\xrightarrow{\;\;\;\;\;}}
\newcommand{\myarrowstar}{\xrightarrow{\;\;*\;\;}}
\newcommand{\fivespaces}{\;\;\;\;\;}
\newcommand{\tenspaces}{\fivespaces\fivespaces}
\newcommand{\twentyspaces}{\tenspaces\tenspaces}
\newcommand{\thirtyspaces}{\twentyspaces\tenspaces}
\newcommand{\fortyspaces}{\twentyspaces\twentyspaces}
\newcommand{\interf}{\fivespaces}
\newcommand{\mylabel}[1]{\ \textbf{(#1)}}
\newcommand{\chmath}[1]{\mbox{`}#1\mbox{'}}

\newcommand{\Eval}[1]{\mathrm{eval} \; #1}
\newcommand{\Esimple}[2]{\mathrm{esimp} \; #1\;#2}
\newcommand{\Efunction}[2]{\mathrm{efunc} \; #1\;#2}
\newcommand{\Efold}[2]{\mathrm{efold} \; #1\;#2}
\newcommand{\Cconst}[1]{\mathrm{Cconst} \; #1}
\newcommand{\Csimple}[2]{\mathrm{Csimple} \; (#1,\,#2)}
\newcommand{\Cfunc}[1]{\mathrm{Cfunc} \; #1}
\newcommand{\Cfold}[1]{\mathrm{Cfold} \; #1}
\newcommand{\Cclose}[1]{\mathrm{Cclose} \; #1}
\newcommand{\Emptyl}{\{\}}
\newcommand{\Mapl}{map_{s \rightarrow l}}
\newcommand{\Pcap}[2]{\langle#1,\,#2\rangle}
\newcommand{\Pcapp}[3]{\langle#1,\,#2,\,#3\rangle}
\newcommand{\Concatl}{\;}

\newtheorem{proposition}{Proposition}

\sloppy

\title{Efficient List Matching using PEGs}

\author{Sérgio Medeiros\inst{1}, Fabio Mascarenhas\inst{1}, Roberto Ierusalimschy\inst{1} }


\address{Department of Computer Science -- PUC-Rio -- Rio de Janeiro -- Brazil
  \email{\{smedeiros,roberto\}@inf.puc-rio.br, mascarenhas@acm.org}
}

\begin{document} 

\maketitle

\begin{abstract}
Parsing Expression Grammars (PEGs) are a recognition-based foundation
for describing syntax that renewed interest in top-down parsing
approaches. We extend the definition of PEGs to support the matching
of structured data in the form of lists, with a corresponding operational semantics.
We also extend a virtual parsing machine from a previous work where
each PEG can be transformed to a program for this machine, and extend the
previous correctness proofs of this transformation for the new list patterns, along
with possible optimizations. We also present an approach for formally adding 
semantic actions to PEGs and their parsing machine programs. Benchmarks validate
the effectiveness of our optimizations and the efficiency of our approach compared
to other PEG-based tool.
\end{abstract}

%\keywords{parsing machine, Parsing Expression Grammars, pattern matching, virtual machines}

\section{Introduction}

Parsing Expression Grammars (PEGs)~\cite{ford:peg} are a formalism for language recognition
 which renewed interest in top-down parsing approaches. The PEG formalism gives a convenient
syntax for describing top-down parsers for unambiguous languages. The core of the formalism
is a form of limited backtracking via \emph{ordered choice}. The limited backtracking gives
PEGs the property of composability, meaning that a PEG can be used by another PEG just by making
sure the names of their productions do not clash. This also lets PEG implementations integrate
cleanly with hand-written parsers. These properties make PEGs very attractive for building
dynamically-extensible parsers.

LPEG~\cite{roberto:lpeg} is a pattern-matching tool for the Lua language ~\cite{pil2} that uses
PEGs to describe patterns instead of the more popular Perl-like ``regular expressions" (regexes). 
The implementation of LPEG uses a \emph{virtual parsing machine},
where each pattern translates to a program for this machine~\cite{dls:lpeg}. LPEG builds these
programs at runtime, dynamically composing smaller programs into bigger programs, thus taking
advantage of the composability of PEGs. PEGs limited backtracking is also reflected on this
parsing machine through its use of a stack to manage backtrack information.

This paper is a continuation of a previous work~\cite{dls:lpeg} where we 
presented an alternative operational semantic for PEGs (based on natural semantics), and
a formal specification of the parsing machine, along with a  correctness proof for our
transformation of PEGs to programs of the machine.

Both the original PEG formalism and our previous parsing machine assume that the subject
a PEG recognizes is a string of characters. In this paper, we extend both formalisms to
parse structured data in the form of Lisp-style lists (a possibly empty list where each element 
can be an atom or another list). We show that our previous results hold when matching lists
or slices of lists that are isomorphic to strings, and give proofs for the correctness of the
translation of our new constructions.

Extending PEGs to match structured data make PEGs useful for a larger part of the compilation/interpretation
pipeline. A PEG-based scannerless parser can construct an abstract syntax tree, and PEG-based tree
walkers and transformers can implement analysis and optimization passes on this tree, then either compiling
it to a target language or evaluating it. Using the same abstraction (PEGs) for the whole pipeline of simple
domain-specific languages can make them easier for programmers to design and implement.

Adding a few extra instructions to the parsing machine enables transformation of certain
pattern classes to more efficient programs, and we also present these optimizations. We
restrict ourselves to optimizations on list patterns, as our previous work has covered more general
parsing machine optimizations. For each optimization, we present a proof of its correctness and a benchmark
showing how effective it is.

We also present an extension to the PEG formalism to include lazy semantic actions, by which
we can extract useful information from structured data, instead of just knowing if it fits a pattern.
Our approach for semantic actions is lazy because the match does not execute the actions, only collects enough
information to execute them later (in a typical implementation, right after the match finishes). This also
means that semantic actions are free to have side-effects even in the presence of backtracking.

Finally, we review related work on parsing structured data and on semantic actions for PEGs. We also present another set
of benchmarks comparing our extended LPEG with a PEG-based tool of similar power, showing an order-of-magnitude
improvement.

The rest of this paper is organized as follows: Section~\ref{sec:lists} extends
PEGs with list patterns; Section~\ref{sec:machine} describes the virtual parsing machine;
proves the transformation between PEGs and their
corresponding programs for the machine is correct; Section~\ref{sec:optimizations}
describes optimizations for list patterns in our machine;
Section~\ref{sec:captures} extends PEGs with lazy semantic actions and shows how to execute them;
Section~\ref{sec:related} reviews some related work; finally,
Section~\ref{sec:conclusions} summarizes our results.

\section{Extending PEGs for Lists}
\label{sec:lists}

In~\cite{dls:lpeg}, we described a \texttt{match} relation for PEGs, 
where we defined the relation \texttt{match} on
$\mathrm{Grammar} \times \mathrm{Pattern} \times \Sigma^{*} \times \mathcal{N} \times (\mathcal{N} \cup \{\Nothing\})$.
Given a grammar (a map from variables to patterns), a pattern, a subject string, and a position (the subject starts at position $1$),
the relation gives us either the position after the match (possibly the length of the subject plus $1$) or \Nothing, depending on
whether the pattern matches the subject or not. We use 
$\Matchf{G}{p}{s}{i} \leadsto j$ to indicate that $(G, p, s, i, j) \in \texttt{match}$.

In this paper, we are considering lists to be Lisp-style lists, made up from atoms and other lists. We will restrict ourselves
to only characters as atoms. We represent the empty list as \Emptyl. Lists are inductively defined by the operator \emph{:}
(also known as cons). If $c$ is an atom and $l$ is a list then $c:l$ is a list, and if $l_1$ and $l_2$ are lists then $l_1:l_2$ is
a list. The first argument of $:$ is the head of the list and the second is the tail. We will use $\{ e_1 e_2 \ldots e_n \}$ as
another way to write $e_1:e_2:\ldots :e_n:\Emptyl$.

We will use $|l|$ to represent the number of elements of list $l$, and its inductive definition is trivial. We will use $l[i]$ to
denote the $i^{th}$ element of the list, starting from $1$, which also has a straightforward inductive definition. List concatenation
is represented by juxtaposition ($l_1l_2$ is the list with all elements of $l_1$ followed by all elements from $l_2$, not to be
confused with $l_1:l_2$, which is a list with $l_1$ as the first element followed by the elements of $l_2$).

Now we can define a new relation $\texttt{match}_L$ on
$\mathrm{Grammar} \times \mathrm{Pattern} \times \mathrm{List} \times \mathcal{N} \times (\mathcal{N} \cup \{\Nothing\})$.
This relation gives us the position in the list after trying to match a pattern given a starting position and a grammar, or
\Nothing if the list does not match the pattern. As with \texttt{match}, we also have a notation
$\Matchl{G}{p}{s}{i} \leadsto j$ to indicate that $(G, p, s, i, j) \in \texttt{match}_L$.

Table~\ref{tab:patterns} presents the abstract syntax of PEG patterns with the new \emph{list pattern} $\{p\}$, and Figure~\ref{fig:semgr} presents an operational semantics of $\texttt{match}_L$ given as rules on the pattern structure. Except for rules $list.1$ and $list.2$, all semantic rules of $\texttt{match}_L$ are taken straight from \texttt{match}. We have that $\Matchl{G}{p}{s}{i} \leadsto j$ if we can use the rules to  build a finite derivation tree for this proposition.

%
\begin{table}
\centering
\begin{tabular}{|c|} \hline
\chmath{.}            $\in$ Pattern  \\ %\hline
\chmath{c}            $\in$ Pattern  \\ %\hline
If $(A, p)$ $\in$ Grammar then  $A$     $\in$ Pattern  \\ %\hline
If $p$   $\in$ Pattern then      
  $p^*$, $!p$, $\&p$, and $\{p\}$  $\in$ Pattern \\ %\hline	
If $p_{1}$ and $p_{2}$ $\in$ Pattern then
 $p_{1}p_{2}$ and $p_{1}/p_{2}$ $\in$ Pattern \\ \hline
\end{tabular}
\caption{Syntax of PEG patterns}
\label{tab:patterns}
\end{table}
%

Rules $list.1$ and $list.2$ formlalize the notion that a list pattern $\{p\}$ only succeeds if the current element of the
subject is also a list and if $p$ matches this whole sublist from the first element. Thus the pattern $\{ \chmath{a} \chmath{b} \}$ matches
the list $\{ \chmath{a} \chmath{b} \}$ but not the list $\{ \chmath{a} \chmath{b} \chmath{c} \}$, or the atom $\chmath{a}$.

The set of character strings is isomorphic to the set of lists where all elements are characters plus the empty list. Lets define
$\Mapl$ as the natural mapping from strings to lists, that is, the empty string maps to the empty list, and a string
$\chmath{c_1} \ldots \chmath{c_n} $ maps to $\{ \chmath{c_1} \ldots \chmath{c_n} \}$. In other words, if $s$ is a string,
$|s| = |\Mapl(s)|$ and $s[i] = \Mapl(s)[i]$ for $1 \leq i \leq |s|$. We then have:
%
\begin{equation*}
\Matchf{G}{p}{s}{i} \leadsto j \;\;\mbox{iff}\;\; \Matchl{G}{p}{\Mapl(s)}{i} \leadsto j.
\end{equation*}
%\begin{proposition}
%$\Matchf{G}{p}{s}{i} \leadsto j$ iff $\Matchl{G}{p}{\Mapl(s)}{i}$.
%\end{proposition}
%
with a trivial inductive proof on the height of the derivation tree, given the semantic rules are identical. In other words,
our extended semantics is identical to the regular PEG semantics when we are dealing with string-like lists as subjects.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Operational Semantics of PEG Patterns with Grammars and Lists %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure*}
{
\footnotesize
\begin{align*}
%Matching a given character
& \textbf{Character} \tenspaces 
{\frac{s[i] = \chmath{c}}{\Matchl{g}{\chmath{c}}{s}{i} \leadsto \Just{i+1}}} \mylabel{ch.1} \tenspaces
{\frac{s[i] \neq \chmath{c}}{\Matchl{g}{\chmath{c}}{s}{i} \leadsto \Nothing}} \mylabel{ch.2} \\ \\
%Matching any element
& \textbf{Any Element} \tenspaces
{\frac{i \leq |s|}{\Matchl{g}{.}{s}{i} \leadsto \Just{i+1}}} \mylabel{any.1} \tenspaces
{\frac{i > |s|}{\Matchl{g}{.}{s}{i} \leadsto \Nothing}} \mylabel{any.2} \\ \\
%Not
& \textbf{Not Predicate} \tenspaces \fivespaces
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Nothing} 
	{\Matchl{g}{!p}{s}{i} \leadsto \Just{i}}} \mylabel{not.1} \tenspaces
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Just{i+j}}
	{\Matchl{g}{!p}{s}{i} \leadsto \Nothing}} \mylabel{not.2} \\ \\
%And
& \textbf{And Predicate} \tenspaces \fivespaces
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Just{i+j}}
	{\Matchl{g}{\&p}{s}{i} \leadsto \Just{i}}} \mylabel{and.1} \tenspaces
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Nothing}
	{\Matchl{g}{\&p}{s}{i} \leadsto \Nothing}} \mylabel{and.2} \\ \\
%Concatenation
& \textbf{Concatenation} \twentyspaces
{\frac{\Matchl{g}{p_{1}}{s}{i} \leadsto \Just{i+j} \interf \Matchl{g}{p_{2}}{s}{i+j} \leadsto \Just{i+j+k}}
{\Matchl{g}{p_{1}p_{2}}{s}{i} \leadsto \Just{i+j+k}}} \mylabel{con.1} \\ \\
& \fivespaces
{\frac{\Matchl{g}{p_{1}}{s}{i} \leadsto \Just{i+j} \interf \Matchl{g}{p_{2}}{s}{i+j} \leadsto \Nothing}
	{\Matchl{g}{p_{1}p_{2}}{s}{i} \leadsto \Nothing}} \mylabel{con.2} \fivespaces
{\frac{\Matchl{g}{p_{1}}{s}{i} \leadsto \Nothing}
	{\Matchl{g}{p_{1}p_{2}}{s}{i} \leadsto \Nothing}} \mylabel{con.3} \\ \\
%Ordered Choice
& \textbf{Ordered Choice} \twentyspaces
{\frac{\Matchl{g}{p_{1}}{s}{i} \leadsto \Nothing \interf \Matchl{g}{p_{2}}{s}{i} \leadsto \Nothing}
	{\Matchl{g}{p_{1}/p_{2}}{s}{i} \leadsto \Nothing}} \mylabel{ord.1} \\ \\
& \fivespaces
{\frac{\Matchl{g}{p_{1}}{s}{i} \leadsto \Just{i+j}}
	{\Matchl{g}{p_{1}/p_{2}}{s}{i} \leadsto \Just{i+j}}} \mylabel{ord.2} \tenspaces
{\frac{\Matchl{g}{p_{1}}{s}{i} \leadsto \Nothing \interf \Matchl{g}{p_{2}}{s}{i} \leadsto \Just{i+k}}
	{\Matchl{g}{p_{1}/p_{2}}{s}{i} \leadsto \Just{i+k}}} \mylabel{ord.3} \\ \\ 
%Repetition
& \textbf{Repetition} \;\;\;
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Just{i+j} \interf \Matchl{g}{p^*}{s}{i+j} \leadsto \Just{i+j+k}}
	{\Matchl{g}{p^*}{s}{i} \leadsto \Just{i+j+k}}} \mylabel{rep.1} \;\;
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Nothing}
	{\Matchl{g}{p^*}{s}{i} \leadsto \Just{i}}} \mylabel{rep.2} \\ \\
%Variable
& \textbf{Variables} \twentyspaces
{\frac{\Matchl{g}{g(A_{k})}{s}{i} \leadsto \Just{i+j}}
	{\Matchl{g}{A_{k}}{s}{i} \leadsto \Just{i+j}}} \mylabel{var.1} \tenspaces
{\frac{\Matchl{g}{g(A_{k})}{s}{i} \leadsto \Nothing}
	{\Matchl{g}{A_{k}}{s}{i} \leadsto \Nothing}} \mylabel{var.2} \\ \\
%Closed Grammars
& \textbf{Closed Grammars} \tenspaces \fivespaces
{\frac{\Matchl{g}{g(A_{k})}{s}{i} \leadsto \Just{i+j}}
	{\Matchl{g^{\prime}}{(g,A_{k})}{s}{i} \leadsto \Just{i+j}}} \mylabel{cg.1} \tenspaces
{\frac{\Matchl{g}{g(A_{k})}{s}{i} \leadsto \Nothing}
	{\Matchl{g^{\prime}}{(g,A_{k})}{s}{i} \leadsto \Nothing}} \mylabel{cg.2} \\ \\
%Lists
& \textbf{List} \tenspaces
{\frac{\Matchl{g}{p}{s[i]}{1} \leadsto \Just{$|s[i]|$+ 1}}
	{\Matchl{g}{\{p\}}{s}{i} \leadsto \Just{i+1}}} \mylabel{list.1} \tenspaces
{\frac{\Matchl{g}{p}{s[i]}{1} \neq \Just{$|s[i]|$ + 1}}
	{\Matchl{g}{\{p\}}{s}{i} \leadsto \Nothing}} \mylabel{list.2}
\end{align*}
\caption{Operational Semantics of PEGs with Lists}
\label{fig:semgr}
}
\end{figure*}


\section{Parsing Machine}
\label{sec:machine}

In~\cite{dls:lpeg} we also presented the semantics for a parsing machine for PEGs, along with a transformation
from PEG patterns to programs that this machine executes. The parsing machine is the core of LPEG, our implementation
of PEGs, and is emphasizes implementation efficiency without sacrificing the expressive and parsing power of
PEGs.

The machine has a program counter to address the next instruction to execute,
a  register to hold the current position in the subject, and a stack that the machine uses for pushing
call and backtrack frames. A call frame is just a return address for the program counter, and a backtrack frame is an
address for the program counter and a position in the subject. The machine's instructions
manipulate on the program counter, position register and the stack.

To be able to translate list patterns to the parsing machine, we need to add another register to hold the current
subject. We also need to be able to store \emph{list frames} in the stack, a list frame is a subject and a position. These
two additions let we save the current subject and position in the stack before starting to process a sub-list that is an element
of the current subject. We also need to add two new instructions:

\begin{description}
\item[\texttt{Open}] pushes a list frame on the stack, then changes the subject to the element at the current position. The  current position becomes $1$, the start of the new subject. Fails if the element at the current position is not a list.

\item[\texttt{Close}] if the current position points past the end of the subject, pops the top entry from the stack (which will be a
list frame), setting the subject to the subject in the popped frame and the position to the position in the frame plus one. Fails if
the current position is not pointing past the end of the subject.
\end{description}

Formally, the program counter, the subject and position registers, and the stack form a machine state. We can represent
it as a tuple $\mathcal{N} \times \mathrm{List} \times \mathcal{N} \times \mathrm{Stack}$, in the order above. A machine state can also be a failure state, represented by $\Sfail{e}$, where $e$ is the stack. Stacks are lists of
$(\mathcal{N} \times \mathrm{List} \times \mathcal{N}) \cup (\mathrm{List} \times \mathcal{N})
\cup \mathcal{N}$, where $\mathcal{N} \times \mathrm{List} \times \mathcal{N}$
represents a backtrack frame, $\mathrm{List} \times \mathcal{N}$ represents
a list frame, and $\mathcal{N}$ represents a call frame.

Figure~\ref{fig:semantics} presents the operational semantics of the parsing
machine as a relation between machine states. The program $\mathcal{P}$ that the
machine executes is implicit. The relation $\xrightarrow{\mathrm{Instruction}}$ relates two states when \emph{pc} in the first state addresses a instruction matching the label, and the guard (if present) is valid.
%
\begin{figure*}
{
\footnotesize
\[
\begin{array}{rlll}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{Char}{x}}%
      {\Sstate{pc+1}{s}{i+1}{e}}{\Subi=x}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{Char}{x}}%
      {\Sfail{e}}{\Subi\not=x}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{Any}{}}%
      {\Sstate{pc+1}{s}{i+1}{e}}{i+1 \leq |\Sub|}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{Any}{}}%
      {\Sfail{e}}{i+1 > |\Sub|}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{Choice}{l}}%
      {\Sstate{pc+1}{s}{i}{(pc+l,s,i):e}}{}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{Jump}{l}}%
      {\Sstate{pc+l}{s}{i}{e}}{}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{Call}{l}}%
      {\Sstate{pc+l}{s}{i}{(pc+1):e}}{}
\Sstep{\Sstate{pc}{s}{i}{pc_1:e}}{\Ia{Return}{}}%
      {\Sstate{pc_1}{s}{i}{e}}{}
\Sstep{\Sstate{pc}{s}{i}{h:e}}{\Ia{Commit}{l}}%
      {\Sstate{pc+l}{s}{i}{e}}{}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{Fail}{}}%
      {\Sfail{e}}{}
\Sstep{\Sfail{pc:e}}{\mbox{\emph{any}}}%
      {\Sfail{e}}{}
\Sstep{\Sfail{(s,i):e}}{\mbox{\emph{any}}}%
      {\Sfail{e}}{}
\Sstep{\Sfail{(pc,s,i):e}}{\mbox{\emph{any}}}%
      {\Sstate{pc}{s}{i}{e}}{}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{Open}{}}%
      {\Sstate{pc+1}{\Subi}{1}{(s,i):e}}{\Subi \in List}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{Open}{}}%
      {\Sfail{e}}{\Subi \notin List}
\Sstep{\Sstate{pc}{s}{i}{(s_1,i_1):e}}{\Ia{Close}{}}%
      {\Sstate{pc+1}{s_1}{i_1+1}{e}}{i=|\Sub|+1}
\Sstep{\Sstate{pc}{s}{i}{(s_1,i_1):e}}{\Ia{Close}{}}%
      {\Sfail{e}}{i\neq|\Sub|+1}
\end{array}
\]
}
\caption{Operational Semantics of the Parsing Machine}
\label{fig:semantics}
\end{figure*}

The process of translating a pattern into a program is bottom up, and
we do it at runtime. The simplest patterns translate to simple programs, and then we 
combine programs according to the rules of each PEG operation.
Programs are opaque entities for the translation process: the pattern
that originated them is not important, as long as the programs are
valid. The process is fully incremental, and combining
programs is a simple matter of concatenating their texts.

In~\cite{dls:lpeg}, we represent the compilation process
using a transformation function $\mathrm{\Pi}$ on the domain
 $\mathrm{Grammar} \times \mathcal{N} \times \mathrm{Pattern}$,
where $\Pi(g,i,p)$ is the translation of pattern $p$ in the
context of grammar $g$, with $i$ an index used just for compiling
references to other rules in the grammar (the mechanism is fully explained
in our previous work). We will also use the notation $|\Pi(g,i,p)|$, which
means the number of instructions of the program $\Pi(g,i,p)$.

The proof of correctness of this transformation is an induction on derivation
trees. We keep all the transformation rules of the previous work, and it's
straightforward to check the previous proof remains valid. We just have to extend
the proof for our two new induction steps related to the $list.1$ and $list.2$ rules
of $\texttt{match}_L$.

Given a PEG grammar $g$, a position $i$ relative to the beginning of the grammar,
and a pattern $\{p\}$, we have the following transformation to the
virtual machine instructions:
%
\begin{equation*}
\begin{split}
\Pi(g, i, \{p\}) \equiv \;
	&{\tt Open} \\
	&\Pi(g, i+1, p)\\
	&{\tt Close}
\end{split}
\end{equation*}
%
The transformation for a list pattern $\{p\}$ just puts a pair of instructions \texttt{Open-Close}
around the pattern $p$.

Now lets do our two induction steps. First we are going to prove this:
%
\begin{equation*}
\begin{split}
&\texttt{If } \Matchl{g}{\{p\}}{s}{i} = \Just{i+1} \texttt{ then}\\
&\Sstepp{\Sstate{pc}{s}{i}{e}}{\Pi(g,i,\{p\})}
	{\Sstate{pc + |\Pi(g,i,p)| + 2}{s}{i+1}{e}}{}
\end{split}
\end{equation*}
%
This case is related to the semantic rule $list.1$,
where $p$ matches all of the contents of element $i$ in the current subject.
We have the following sequence of transitions:
%
\begin{align*}
\xrightarrow{Open} \; &
	{\Sstate{pc + 1}{s[i]}{1}{(s, i):e}} \\
\xrightarrow{\Pi(g, i+1, p)} \; &
	{\Sstate{pc + |\Pi(g,i,p)| + 1}{s[i]}{|s[i]|+1}{(s, i):e}} \\
\xrightarrow{Close} \; &
	{\Sstate{pc + |\Pi(g,i,p)| + 2}{s}{i+1}{e}}
\end{align*}
%
After the \texttt{Open} instruction, the subject becomes
$s[i]$, and the current position is $1$. By induction
we know the execution of $\Pi(g, i+1, p)$ leads to
$\Sstate{pc + |\Pi(g,i,p)| + 1}{s[i]}{|s[i]|+1}{(s, i):e}$,
and after the \texttt{Close} instruction we reach the final
state $\Sstate{pc + |\Pi(g,i,p)| + 2}{s}{i+1}{e}$.

Now we need to prove this:
%
\begin{equation*}
\begin{split}
&\texttt{If } \Matchl{g}{\{p\}}{s}{i} = \Nothing \texttt{ then}\\
&\Sstepp{\Sstate{pc}{s}{i}{e}}{\Pi(g,i,\{p\})}
	{\Sfail{e}}{}
\end{split}
\end{equation*}
%
This case is related to the semantic rule $list.2$,
where $p$ does not match the contents of element $i$, or matches just
part of them. Considering $n < |s[i]|+1$,  if $p$ matches the first $n$ elements
of element $i$ then we have the following sequence of transitions:
%
\begin{align*}
\xrightarrow{Open} \; &
	{\Sstate{pc + 1}{s[i]}{1}{(s, i):e}} \\
\xrightarrow{\Pi(g, i+1, p)} \; &
	{\Sstate{pc + |\Pi(g,i,p)| + 1}{s[i]}{n}{(s, i):e}} \\
\xrightarrow{Close} \; &
	{\Sfail{e}}{}
\end{align*}
%
As $n < |s[i]|+1$ the execution of the \texttt{Close}
instruction leads the machine to a failure state. There is also the case $p$ fails:
%
\begin{align*}
\xrightarrow{Open} \; &
	{\Sstate{pc + 1}{s[i]}{1}{(s, i):e}} \\
\xrightarrow{\Pi(g, i+1, p)} \; &
	{\Sstate{pc + |\Pi(g,i,p)| + 1}{s[i]}{n}{(s, i):e}} \\
\xrightarrow{Close} \; &
	{\Sfail{(s,i):e}}{} \\
\rightarrow \; &
	{\Sfail{e}}{}
\end{align*}
%
This completes our proof. We have now extended both PEGs and our parsing machine to do
matching on list-structured data. In the next section we will review a couple ways of making
this more efficient.

\section{Optimizations}
\label{sec:optimizations}

The previous section showed how to compile list patterns to our parsing machine, and proved the
correctness of this transformation. In several cases, though, we can make the resulting program more efficient,
avoiding unecessary pushs and pops on the machine's stack. This section shows another way
of compiling some list patterns by using pattern identities and a few extra machine instructions, generating
more efficient programs.

Figure~\ref{fig:optimizations} lists the instructions we are adding to the machine and their
semantics. Let's start with a very common pattern, $\{ \chmath{c_1} \ldots \chmath{c_n} \}$, that is, a pattern that
matches a list of $n$ characters. The current program for this pattern is an \texttt{Open} instruction
followed by a sequence of \texttt{Char} instructions and a \texttt{Close} instruction. We can
compile this pattern to a single \texttt{String} instruction with the string ``$c_{1} \ldots c_{2}$'' as its 
argument.

%
\begin{figure*}
{\footnotesize
\[
\begin{array}{rlll}
\Sstep{ \Sstate{pc}{s}{i}{e} }{ \Ia{String}{x} }{ \Sstate{pc+1}{s}{i+1}{e} }{ s[i] = \Mapl(x) }
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{String}{x}}%
      {\Sfail{e}}{s[i] \neq \Mapl(x)}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Iaa{TestString}{l}{x}}%
      {\Sstate{pc+1}{s}{i+1}{e}}{s[i] = \Mapl(x)}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Iaa{TestString}{l}{x}}%
      {\Sstate{pc+l}{s}{i}{e}}{s[i] \neq \Mapl(x)}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{NotAny}{}}%
      {\Sstate{pc+1}{s}{i}{e}}{i > |s|}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{NotAny}{}}%
      {\Sfail{e}}{i \leq |s|}
\end{array}
\]
}
\caption{Operational Semantics of Specialized Instructions for Lists}
\label{fig:optimizations}
\end{figure*}

Now that we have a single instruction that matches a whole list of characters (a list that is isomorphic to a string),
we can do \emph{head-fail} optimizations on these tests by having a complementary \texttt{TestString} instruction
that jumps to a label instead of failing if it does not match. This kind of failure is very common when we
have a pattern like $\{ \chmath{c_1} \ldots \chmath{c_n} \} p_1 / p_2$, such as when matching against a tree that uses strings in the
first element as tags. We can avoid pushing a backtrack entry that will be discarded most of the time
when trying to match the tag. The compilation for the pattern above becomes:
%
\begin{equation*}
\begin{split}
\Pi(g,x, \{c_{1} \ldots c_{n} \} p_1 / p_{2}) \equiv \;
	&{\tt TestString} \; |\Pi(g,x,p_{1})| + 3 \;\; \chmath{c_1} \ldots \chmath{c_n}  \\
	&{\tt Choice} \; |\Pi(g,x,p_{1})| + 2 \;\;\; 1\\
	&\Pi(g,x+2,p_{1})\\
	&{\tt Commit } \; |\Pi(g,x,p_{2})| + 1\\
	&\Pi(g,x+|\Pi(g,x,p_1)|+3,p_{2})
\end{split}
\end{equation*}
%
Notice that now the \texttt{Choice} instruction takes an offset, which is subtracted from the current position
when pushing a new backtrack entry. An offset of zero is assumed if an offset is not provided.

In case of an unsuccessful match of $\{\chmath{c_1} \ldots \chmath{c_n}\}$ and a successful
match of $p_2$, we have the following sequence of transitions:
\begin{align*}
\xrightarrow{TestString} &
	{\Sstate{pc + |\Pi(g,x,p_{1})| + 3}{s}{i}{e}} \\
\xrightarrow{\Pi(g,x+|\Pi(g,x,p_1)|+3,p_{2})} &
    {\Sstate{pc + |\Pi(g,x, \{\chmath{c_1} \dots \chmath{c_n} \} p_1 / p_2)|}{s}{i+k}{e}}
\end{align*}
which is correct by induction on the correctness of $p_{2}$'s compilation.

Finally, there is an interesting optimization derived from an identity between patterns. The natural way
of writing a choice between two list patterns is $\{p_1\} / \{p_2\}$. This compiles to a \texttt{Choice} followed by
an \texttt{Open} instruction, followed by the compilation of $p_1$ and a \texttt{Close}, then a \texttt{Commit}, another
\texttt{Open}, the compilation of $p_2$, and a final \texttt{Close} instruction. But when $p_1$ fails we end up trying
to match $p_2$ against the same subject, and we have an unecessary stack pop and push (plus unecessary changes of the
current subject, which can have implementation costs). The naive optimization is to transform this pattern to
$\{ p_1 / p_2 \}$, but now if $p_1$ is a partial match and $p_2$ is a full match the new pattern will fail where
the previous one would succeed. We can correct this by transforming the original pattern to $\{ p_1 !. / p_2 \}$.

Now a partial match of $p_1$ will fail the antecedent of the choice, and if $p_2$ is a full match then the whole pattern succeeds,
as in the original. By using the new \texttt{NotAny} instruction to compile $!.$, the new pattern compiles to:
%
\begin{equation*}
\begin{split}
\Pi(g, x, \{ p_1 !. / p_2\}) \equiv \;
	&{\tt Open} \;  \\
	&{\tt Choice} \; |\Pi(g,x,p_1)| + 3 \\
	&\Pi(g, x+2, p_1)\\
	&{\tt NotAny } \; \\
	&{\tt Commit } \; |\Pi(g,x,p_2)| + 1\\
	&\Pi(g, x + |\Pi(g,x,p_1)| + 4, p_2) \\
	&{\tt Close} \; 
\end{split}
\end{equation*}
%
Which avoids the extra work of the original pattern, and incidentally opens the patterns to further head-fail optimization. 
A full proof of the identity, and the correctness of compiling $!.$ to \texttt{NotAny}, are straightforward inductions on
derivation trees.

We have implemented these optimizations on LPEG, and evaluated their effectiveness on a few simple benchmarks. The
results are summarized on Figure~\ref{fig:microbench}. The graph shows the running time of the benchmarks for
the base LPEG, LPEG with the string optimization, and LPEG with the string and list choice optimization. 
The benchmarks are on the vertical axis: the \emph{string} benchmark uses a concatenation of string-like
patterns (150,000 iterations), the \emph{headfail} benchmark uses an ordered choice of these patterns (15,000 iterations), and the \emph{choice} benchmark uses an ordered choice of lists of string-like patterns (40,000 iterations). The benchmarks with ordered choice use subjects that match each alternative of the choice.

% TODO: add graph here

\section{Captures}
\label{sec:captures}

In LPEG, a capture is a mix of conventional captures with semantic
actions. In order to add captures, we need to change the $\texttt{match}_L$
relation, which now becomes:
$\mathrm{Grammar} \times \mathrm{Pattern} \times \mathrm{List} \times \mathcal{N} \times ((\mathcal{N}, Capture^*) \cup \{\Nothing\})$,
where $Capture^*$ represents a list of captures.
%We will use the notation
%$\Matchl{G}{p}{s}{i} \leadsto (j,c)$ to indicate that $(G, p, s, i, (j, c)) \in \texttt{match}_L$.

The use of captures does not affect the matching of a subject, if a matching was successful without the
use of captures, it will still be successful if we do it again using captures. Therefore, the use of capture
patterns, whose syntax is listed in Table~\ref{tab:captures}, will only affect the list of captures.

We have four kinds of captures: \emph{simple}, which captures a given portion of the subject;
\emph{constant}, which creates a constant capture; \emph{function}, which calls a given function
with a list of values obtained from the captures; and \emph{fold}, which folds (or reduces) a list
of values, producing a single value.
%
\begin{table}
\centering
\begin{tabular}{|c|} \hline
If $v$ $\in$ Value then $\Pcap{const}{v}$ $\in$ Pattern  \\ %\hline
If $p$ $\in$ Pattern then $\Pcap{simp}{p}$ $\in$ Pattern  \\ %\hline
If $p$ $\in$ Pattern and $f$ $\in$ $Value^* \times Value^*$ then $\Pcap{func}{f}$ $\in$ Pattern \\ %\hline
If $p$ $\in$ Pattern and $f$ $\in$ $Value \times Value \times Value$ then $\Pcap{fold}{f}$ $\in$ Pattern \\ \hline
\end{tabular}
\caption{Syntax of Capture Patterns}
\label{tab:captures}
\end{table}
%
Figure~\ref{fig:captures} presents the new operational semantics of $\texttt{match}_L$ when dealing with captures.
As the semantics of $\texttt{match}_L$ remains the same when a pattern fails, we did not repeat the rules related
to an unsuccessful matching for the previous patterns. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Operational Semantics of PEG with Captures %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{figure*}
{
\footnotesize
\begin{align*}
%Matching a given character
& \textbf{Character} \fivespaces 
{\frac{s[i] = \chmath{c}}{\Matchl{g}{\chmath{c}}{s}{i} \leadsto \Justc{i+1}{\Emptyl}}} \mylabel{ch.1} \fivespaces
%Matching any element
\textbf{Any Element} \fivespaces
{\frac{i \leq |s|}{\Matchl{g}{.}{s}{i} \leadsto \Justc{i+1}{\Emptyl}}} \mylabel{any.1}  \\ \\
%Not
& \textbf{Not Predicate} \fivespaces
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Nothing} 
	{\Matchl{g}{!p}{s}{i} \leadsto \Justc{i}{\Emptyl}}} \mylabel{not.1} \fivespaces
%And
\textbf{And Predicate} \fivespaces
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Justc{i+j}{c}}
	{\Matchl{g}{\&p}{s}{i} \leadsto \Justc{i}{c}}} \mylabel{and.1}  \\ \\
%Concatenation
& \textbf{Concatenation} \twentyspaces
{\frac{\Matchl{g}{p_{1}}{s}{i} \leadsto \Justc{i+j}{c_1} \interf \Matchl{g}{p_{2}}{s}{i+j} \leadsto \Justc{i+j+k}{c_2}}
{\Matchl{g}{p_{1}p_{2}}{s}{i} \leadsto \Justc{i+j+k}{c_1 \Concatl c_2}}} \mylabel{con.1} \\ \\
%Ordered Choice
& \textbf{Ordered Choice} \;
{\frac{\Matchl{g}{p_{1}}{s}{i} \leadsto \Justc{i+j}{c_1}}
	{\Matchl{g}{p_{1}/p_{2}}{s}{i} \leadsto \Justc{i+j}{c_1}}} \mylabel{ord.2} \;
{\frac{\Matchl{g}{p_{1}}{s}{i} \leadsto \Nothing \;\;\; \Matchl{g}{p_{2}}{s}{i} \leadsto \Justc{i+k}{c_2}}
	{\Matchl{g}{p_{1}/p_{2}}{s}{i} \leadsto \Justc{i+k}{c_2}}} \mylabel{ord.3} \\ \\ 
%Repetition
& \textbf{Repetition} \;\;
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Justc{i+j}{c} \interf \Matchl{g}{p^*}{s}{i+j} \leadsto \Justc{i+j+k}{c_1}}
	{\Matchl{g}{p^*}{s}{i} \leadsto \Justc{i+j+k}{c \Concatl c_1}}} \mylabel{rep.1} \;\;
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Nothing}
	{\Matchl{g}{p^*}{s}{i} \leadsto \Justc{i}{\Emptyl}}} \mylabel{rep.2} \\ \\
%Variable
& \textbf{Variables} \fivespaces
{\frac{\Matchl{g}{g(A_{k})}{s}{i} \leadsto \Justc{i+j}{c}}
	{\Matchl{g}{A_{k}}{s}{i} \leadsto \Justc{i+j}{c}}} \mylabel{var.1} \fivespaces
%Closed Grammars
\textbf{Closed Grammars} \fivespaces
{\frac{\Matchl{g}{g(A_{k})}{s}{i} \leadsto \Justc{i+j}{c}}
	{\Matchl{g^{\prime}}{(g,A_{k})}{s}{i} \leadsto \Justc{i+j}{c}}} \mylabel{cg.1} \tenspaces \\ \\
%Lists
& \textbf{List} \;\;
{\frac{\Matchl{g}{p}{s[i]}{1} \leadsto \Justc{$|s[i]|$ + 1}{c}}
	{\Matchl{g}{\{p\}}{s}{i} \leadsto \Justc{i+1}{c}}} \mylabel{list.1} \;\;\;
%Matching a Constant Capture
\textbf{Const Capture} \;\;
{\frac{}
	{\Matchl{g}{\Pcap{const}{v}}{s}{i} \leadsto \Justc{i}{\{\Pcap{const}{v}\}}}} \mylabel{const.1} \\ \\
%Matching a Simple Capture
& \textbf{Simple Capture} \tenspaces
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Nothing}
	{\Matchl{g}{\Pcap{simp}{p}}{s}{i} \leadsto \Nothing}} \mylabel{simple.2} \\ \\
& \tenspaces
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Justc{i+j}{c}}
	{\Matchl{g}{\Pcap{simp}{p}}{s}{i} \leadsto \Justc{i+j}{(\Pcapp{simp}{s}{i}):c \Concatl \{\Pcap{close}{j}\}}}} \mylabel{simple.1} \\ \\
%Matching a Function Capture
& \textbf{Function Capture} \tenspaces
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Nothing}
	{\Matchl{g}{\Pcap{func}{f}}{s}{i} \leadsto \Nothing}} \mylabel{func.2} \\ \\
& \tenspaces
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Justc{i+j}{c}}
	{\Matchl{g}{\Pcap{func}{f}}{s}{i} \leadsto \Justc{i+j}{\Pcap{func}{f} \Concatl c \Concatl \{\Pcap{close}{j}\}}}} \mylabel{func.1} \\ \\
%Matching a Fold Capture
& \textbf{Fold Capture} \;
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Nothing}{\Matchl{g}{\Pcap{fold}{f}}{s}{i} \leadsto \Nothing}} \mylabel{fold.2}
\;
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Justc{i+j}{c}}{\Matchl{g}
	{\Pcap{fold}{f}}{s}{i} \leadsto \Justc{i+j}{\Pcap{fold}{f}:c \Concatl \{\Pcap{close}{j}\}}}} \mylabel{fold.1}
\end{align*}
\caption{Operational Semantics of PEG Patterns with Captures}
\label{fig:captures}
}
\end{figure*}

Accordingly, we also need to change the state of the parsing machine and to add new instructions
to deal with captures. The state of our machine is now either a tuple
$\mathcal{N} \times \mathrm{List} \times \mathcal{N} \times \mathrm{Stack} \times \mathrm{Capture^*}$,
where we will use a symbol \emph{k} to denote the list of captures, or $\Sfail{e}$.
Now, a backtrack entry keeps also a list of captures.

\begin{figure*}
{
\footnotesize
\[
\begin{array}{rlll}
\Sstep{\Sstatec{pc}{s}{i}{e}{k}}{\Iaa{Choice}{l}{o}}%
      {\Sstatec{pc+1}{s}{i}{(pc+l,s,i-o,k):e}{k}}{}
\Sstep{\Sfail{(pc,s,i,k):e}}{\mbox{\emph{any}}}%
      {\Sstatec{pc}{s}{i}{e}{k}}{}
\Sstep{\Sstatec{pc}{s}{i}{e}{k}}{\Ia{ConstCap}{v}}%
      {\Sstatec{pc+1}{s}{i}{e}{k \Concatl \{\Pcap{const}{v}\}}}{}
\Sstep{\Sstatec{pc}{s}{i}{e}{k}}{\Ia{SimpCap}{p}}%
      {\Sstatec{pc+1}{s}{i}{e}{k \Concatl \{\Pcapp{simp}{s}{i}\}}}{}
\Sstep{\Sstatec{pc}{s}{i}{e}{k}}{\Ia{FuncCap}{v}}%
      {\Sstatec{pc+1}{s}{i}{e}{k \Concatl \{\Pcap{func}{f}\}}}{}
\Sstep{\Sstatec{pc}{s}{i}{e}{k}}{\Ia{FoldCap}{v}}%
      {\Sstatec{pc+1}{s}{i}{e}{k \Concatl \{\Pcap{fold}{f}\}}}{}
\Sstep{\Sstatec{pc}{s}{i}{e}{k}}{\Ia{CloseCap}{}}%
      {\Sstatec{pc+1}{s}{i}{e}{k \Concatl \{\Pcap{close}{i}\}}}{}
\end{array}
\]
}
\caption{Operational Semantics of the Parsing Machine using Captures}
\label{fig:semcaptures}
\end{figure*}

The new instructions of the parsing machine are:
\texttt{ConstCap}, which pushes a constant capture on the list of captures;
\texttt{SimpCap}, which pusches a simple capture;
\texttt{FuncCap}, which pushes a function capture;
\texttt{FoldCap}, which pushes a fold capture;
and \texttt{CloseCap}, which pushes an entry indicating the end of a capture;
Figure~\ref{fig:semcaptures} presents the semantics of these new instructions, plus the new semantics of
\texttt{Choice} and \texttt{Fail} when there is backtrack entry on the top of the stack.

The compilation of a pattern $\Pcap{const}{v}$, just produces an instruction $ConstCap \; v$. The compilation
of a pattern $\Pcap{simp}{p}$, puts a pair of instructions $SimpCap-CloseCap$ around the program corresponding
to pattern $p$. The compilation of $\Pcap{func}{f}$ and $\Pcap{fold}{f}$ is similar.

The list of captures produced by the $\texttt{match}_L$ relation is equal to list of captures produced by
the parsing machine. The proof is an extension to the previous proof of the $\texttt{match}_L$ relation,
doing an induction on the structure of the PEG patterns.


\subsection{Evaluating the List of Captures}

After the matching, the list of captures is evaluated in order to produce
the actual values.

In case of a constant capture, the final value is already on the list of
captures. In case of a simple capture, the final value is the slice from $i$ until $j-1$ of the subject
$s$. In case of a function capture, the function $f$ is called and receives as its parameters the values
produced from a list of captures. The values returned by $f$ are the final values of that list of captures.

In case of a fold capture, the $f$ function will be called with the values produced from a list of captures.
If the evaluation of a list of captures produces values $v_1, v_2, \ldots, v_n$, we have that
$fold f v_1, v_2, \ldots, v_n$ will produce the value: $f(\ldots f(f(v_1,v_2), v_3) \ldots,v_n)$.
If the list of values has just one value, then the result of $fold f v_1$ is $v_1$. If the list
is empty, the result is unspecified.

The \texttt{eval} function and its auxiliary functions do the job of evaluating a list of captures. The
definition of \texttt{eval} is: $\mathrm{State} \times \mathrm{State}$, where $State$ is a pair
$(\mathrm{Capture^*}, \mathrm{Value^*})$, where $Capture^*$ is a list of captures and $Value$ a list of values.

Functions \texttt{esimp}, \texttt{efunc}, and \texttt{efold} are similar to \texttt{eval}, but get also an
extra state. In case of \texttt{esimp}, the extra state is a tuple $(\mathrm{Subject}, \mathcal{N}, \mathrm{Capture^*})$.
In case of \texttt{efunc} and \texttt{efold}, the extra state is a tuple $(\mathrm{Function}, \mathrm{Capture^*})$.
In all tuples, $Capture^*$ is the list of captures until the beginning of the corresponding capture.
After applying \texttt{eval} to the list of captures constructed by $\mathrm{match}_L$ and an empty list of values,
the result is an empty list of captures and a list of values obtained from the captures.
Notice that the position associated with a close capture is only important when evaluating a simple capture.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Operational Semantics of eval %%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure*}[t]
{
\footnotesize
\begin{align*}
%Not
& %\textbf{eval} \tenspaces
{\frac{}
	{\Eval{(\Emptyl,v)} = (\Emptyl,v)}}  \mylabel{eval.1} \tenspaces 
{\frac{}
	{\Eval{(\Pcap{close}{j}:cs, vs)} = (\Pcap{close}{j}:cs, vs)}} \mylabel{eval.2} \\ \\
%
& {\frac{\Eval{(cs, vs \Concatl \{v\})} = (cs_1, vs_1)}
	{\Eval{(\Pcap{const}{v}:cs, vs)} = (cs_1, vs_1)}} \mylabel{eval.3} \tenspaces
{\frac{\Esimple{(s,i,vs)}{(cs, \Emptyl)} = (cs_1, vs_1)}
	{\Eval{(\Pcap{simp}{s}{i}:cs, vs)} = (cs_1, vs_1)}} \mylabel{eval.4} \\ \\
%
& {\frac{\Efunction{(f,vs)}{(cs, \Emptyl)} = (cs_1, vs_1)}
	{\Eval{(\Pcap{func}{f}:cs, vs)} = (cs_1, vs_1)}} \mylabel{eval.5} \tenspaces
{\frac{\Efold{(f,vs)}{(cs, \Emptyl)} = (cs_1, vs_1)}
	{\Eval{(\Pcap{fold}{f}:cs, vs)} = (cs_1, vs_1)}} \mylabel{eval.6} \\ \\
%
& %\textbf{evsimple} \tenspaces 
{\frac{\Eval{(cs, vs)} = (cs_2, vs_2)}
	{\Esimple{(s,i,vs_1)}{(\Pcap{close}{j}:cs, vs)} = (cs_2, vs_1 \Concatl (sub(s, i, j)):vs_2)}} \mylabel{esimp.1} \\ \\
& {\frac{\Eval{(c:cs, \Emptyl)} = (\Pcap{close}{j}:cs_2, vs_2) \;\;\; \Esimple{(s,i,vs_1)}{(\Pcap{close}{j}:cs_2,vs_2)} = (cs_3, vs_3)}
	{\Esimple{(s,i,vs_1)}{(c:cs, vs)} = (cs_3, vs_3)}}  \, ,c \neq (\Pcap{close}{j}) \mylabel{esimp.2} \\ \\
%
& %\textbf{evfunc} \tenspaces 
{\frac{\Eval{(cs, \Emptyl)} = (cs_2, vs_2)}
	{\Efunction{(f,vs_1)}{(\Pcap{close}{j}:cs, vs)} = (cs_2, vs_1 \Concatl \{f (vs)\} \Concatl vs_2)}} \mylabel{efunc.1} \\ \\
& {\frac{\Eval{(c:cs, \Emptyl)} = (\Pcap{close}{j}:cs_2, vs_2) \;\;\; \Efunction{(f,vs_1)}{(\Pcap{close}{j}):cs_2),vs_2)} = (cs_3, vs_3)}
	{\Efunction{(f,vs_1)}{(c:cs, vs)} = (cs_3, vs_3)}}  \; ,\,c \neq \Pcap{close}{j} \mylabel{efunc.2} \\ \\
%
& %\textbf{evfold} \tenspaces 
{\frac{\Eval{(cs, \Emptyl)} = (cs_2, vs_2)}
	{\Efold{(f,vs_1)}{(\Pcap{close}{j}:cs, vs)} = (cs_2, vs_1 \Concatl (fold (f, vs)):vs_2)}} \mylabel{efold.1} \\ \\
& {\frac{\Eval{(c:cs, \Emptyl)} = (\Pcap{close}{j}:cs_2, vs_2) \;\;\; \Efunction{(f,vs_1)}{(\Pcap{close}{j}:cs_2),vs_2)} = (cs_3, vs_3)}
	{\Efold{(f,vs_1)}{(c:cs, vs)} = (cs_3, vs_3)}}  \; ,\,c \neq \Pcap{close}{j}) \mylabel{efold.2}
\end{align*}
}
\caption{Operational Semantics of \texttt{eval}, \texttt{esimp}, \texttt{efunc}, and \texttt{efold}}
\label{fig:eval}
\end{figure*}




\section{Related Work}
\label{sec:related}

The work most related to ours is OMeta~\cite{warth:ometa},
an object-oriented language with pattern matching facilities based on PEGs. OMeta operates on
lists of host-language objects. In~\cite{warth:thesis},
the principal author of OMeta also presents an operational semantics for list matching. 

While in LPEG there are specific patterns which can produce captures, in OMeta there is no such
distinction, and a successful matching of a pattern always produces a value (generally the value that
would be produced by a single capture in LPEG). OMeta also supports the use of semantic predicates,
a feature that could be implemented in LPEG through the use of match time captures, which are actually
present in the implementation of LPEG but were not discussed here.

An implementation of pattern matching in Scheme supporting lists is described in~\cite{wright:pattern}.
Although the patterns described by Wright have a semantics similar to PEG patterns, there is not possible
to build recursive patterns, as there is no concept similar to a PEG grammar. Scheme patterns also provide
a simplified form of capture, where is possible to capture only a slice of the subject.

The use of regular expression types to describe XML documents is presented
by~\cite{hosoya:xml, hosoya:toplas}. Regular expression types correspond to tree automata, therefore
by using this approach it is possible to recognize a regular tree language, while by using PEGs extended
with lists we can also recognize non-regular tree languages, thus we have a strictly greater recognition power.



\section{Conclusions}
\label{sec:conclusions}

Based on the work of ~\cite{warth:ometa}, we have presented an extension of PEGs which
allows the matching of Lisp-style lists, instead of just characters. According, we have also extended
the definition of our virtual parsing machine for PEGs, and we have proved the transformation
from extended PEG patterns to programs in our parsing machine is correct.

We also added new list-specific instructions to the parsing machine, in order to improve its
performance when dealing with lists, and showed how the perfomance of the machine was affected
by these instructions.

To perform semantic actions, we extended the semantics of the $\mathrm{match}_L$ relation, adding
new patterns related to the capture of values. During the matching, our machine does not perform
semantic actions, it only gathers enough information about the captures so that after the matching
it can produce the corresponding values. The implementation of LPEG includes also other kinds of
captures, such as a match time capture.

We have shown the implementation of our parsing machine for PEGs and its list extension is really fast.
When compared with OMeta, which also implements an extension of PEGs which supports the matching of lists,
the performance of LPEG is almost an order-of-magnitude better.
\bibliographystyle{sbc}
\bibliography{sblp} 


\end{document}
