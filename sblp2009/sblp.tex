\documentclass[12pt]{article}

\usepackage{sbc-template}

\usepackage{graphicx,url}

%\usepackage[brazil]{babel}   
\usepackage[latin1]{inputenc}  
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{alltt}


\newcommand{\Pow}{\, \widehat{} \,\,}
\newcommand{\Match}[3]{\mathrm{match} \;\, #1\;#2\;#3}
\newcommand{\Matchf}[4]{\mathrm{match} \;\, #1\;#2\;#3\;#4}
\newcommand{\Matchl}[4]{\mathrm{match}_L \;\, #1\;#2\;#3\;#4}
\newcommand{\Matchlk}[5]{\mathrm{match}_L \;\, #1\;#2\;#3\;#4\;#5}
\newcommand{\Matchrec}[5]{\mathrm{match} \;\, #1\;#2\;#3\;#4\;#5}
\newcommand{\Nothing}{{\tt fail}}
\newcommand{\Just}[1]{\mbox{#1}}
\newcommand{\Justc}[2]{(\mbox{#1},\,#2)}
\newcommand{\Striple}[3]{(#1,\,#2,\,#3)}
\newcommand{\Sstate}[4]{\langle#1,\,#2,\,#3,\,#4\rangle}
\newcommand{\Sstatec}[5]{\langle#1,\,#2,\,#3,\,#4,\,#5\rangle}
\newcommand{\Sfail}[1]{\mbox{\bf Fail}{\langle#1\rangle}}
\newcommand{\Sstep}[4]{#1 & \xrightarrow{#2} & #3 & #4\\}
\newcommand{\Sstepp}[4]{#1 \xrightarrow{#2} #3\\}
\newcommand{\Ia}[2]{\mbox{{\scriptsize {\tt #1} $#2$}}}
\newcommand{\Iaa}[3]{\mbox{{\scriptsize {\tt #1} $#2$ $#3$}}}
\newcommand{\Fail}{\mbox{\bf Fail}}
\newcommand{\Hd}[1]{\mbox{hd}(#1)}
\newcommand{\Sub}{{s}}
\newcommand{\Subb}{{s_1}}
\newcommand{\Subi}{\Sub [i]}
\newcommand{\Subbi}{\Subb [i]}
\newcommand{\MathN}[1]{\mbox{\emph{#1}}}
\newcommand{\Nat}{\mbox{\bf N}}
\newcommand{\myarrow}{\xrightarrow{\;\;\;\;\;}}
\newcommand{\myarrowstar}{\xrightarrow{\;\;*\;\;}}
\newcommand{\fivespaces}{\;\;\;\;\;}
\newcommand{\tenspaces}{\fivespaces\fivespaces}
\newcommand{\twentyspaces}{\tenspaces\tenspaces}
\newcommand{\thirtyspaces}{\twentyspaces\tenspaces}
\newcommand{\fortyspaces}{\twentyspaces\twentyspaces}
\newcommand{\interf}{\fivespaces}
\newcommand{\mylabel}[1]{\ \textbf{(#1)}}
\newcommand{\chmath}[1]{\mbox{`#1'}}

\newcommand{\Eval}[1]{\mathrm{eval} \; #1}
\newcommand{\Esimple}[2]{\mathrm{esimp} \; #1\;#2}
\newcommand{\Efunction}[2]{\mathrm{efunc} \; #1\;#2}
\newcommand{\Efold}[2]{\mathrm{efold} \; #1\;#2}
\newcommand{\Cconst}[1]{\mathrm{Cconst} \; #1}
\newcommand{\Csimple}[2]{\mathrm{Csimple} \; (#1,\,#2)}
\newcommand{\Cfunc}[1]{\mathrm{Cfunc} \; #1}
\newcommand{\Cfold}[1]{\mathrm{Cfold} \; #1}
\newcommand{\Cclose}[1]{\mathrm{Cclose} \; #1}
\newcommand{\Emptyl}{\{\}}
\newcommand{\Mapl}{map_{s \rightarrow l}}
\newcommand{\Pcap}[2]{\langle#1,\,#2\rangle}
\newcommand{\Pcapp}[3]{\langle#1,\,#2,\,#3\rangle}
\newcommand{\Concatl}{\;}

\newtheorem{proposition}{Proposition}

\sloppy

\title{Efficient List Matching using PEGs}

\author{Sérgio Medeiros\inst{1}, Fabio Mascarenhas\inst{1}, Roberto Ierusalimschy\inst{1} }


\address{Department of Computer Science -- PUC-Rio -- Rio de Janeiro -- Brazil
  \email{\{smedeiros,roberto\}@inf.puc-rio.br, mascarenhas@acm.org}
}

\begin{document} 

\maketitle

\begin{abstract}
Parsing Expression Grammars (PEGs) are a recognition-based foundation
for describing syntax that renewed interest in top-down parsing
approaches. We extend the definition of PEGs to support the matching
of structured data in the form of lists, with a corresponding operational semantics.
We also extend a virtual parsing machine from a previous work where
each PEG can be transformed to a program for this machine, and extend the
previous correctness proofs of this transformation for the new list patterns, along
with possible optimizations. We also present an approach for formally adding 
semantic actions to PEGs and their parsing machine programs. Benchmarks validate
the effectiveness of our optimizations and the efficiency of our approach compared
to other PEG-based tool.
\end{abstract}

%\keywords{parsing machine, Parsing Expression Grammars, pattern matching, virtual machines}

\section{Introduction}

Parsing Expression Grammars (PEGs)~\cite{ford:peg} are a formalism for language recognition
 which renewed interest in top-down parsing approaches. The PEG formalism gives a convenient
syntax for describing top-down parsers for unambiguous languages. The core of the formalism
is a form of limited backtracking via \emph{ordered choice}. The limited backtracking gives
PEGs the property of composability, meaning that a PEG can be used by another PEG just by making
sure the names of their productions do not clash. This also lets PEG implementations integrate
cleanly with hand-written parsers. These properties make PEGs very attractive for building
dynamically-extensible parsers.

LPEG~\cite{roberto:lpeg} is a pattern-matching tool for the Lua language ~\cite{pil2} that uses
PEGs to describe patterns instead of the more popular Perl-like ``regular expressions" (regexes). 
The implementation of LPEG uses a \emph{virtual parsing machine},
where each pattern translates to a program for this machine~\cite{dls:lpeg}. LPEG builds these
programs at runtime, dynamically composing smaller programs into bigger programs, thus taking
advantage of the composability of PEGs. PEGs limited backtracking is also reflected on this
parsing machine through its use of a stack to manage backtrack information.

This paper is a continuation of a previous work~\cite{dls:lpeg} where we 
presented an alternative operational semantic for PEGs (based on natural semantics), and
a formal specification of the parsing machine, along with a  correctness proof for our
transformation of PEGs to programs of the machine.

Both the original PEG formalism and our previous parsing machine assume that the subject
a PEG recognizes is a string of characters. In this paper, we extend both formalisms to
parse structured data in the form of Lisp-style lists (a possibly empty list where each element 
can be an atom or another list). We show that our previous results hold when matching lists
or slices of lists that are isomorphic to strings, and give proofs for the correctness of the
translation of our new constructions.

Extending PEGs to match structured data make PEGs useful for a larger part of the compilation/interpretation
pipeline. A PEG-based scannerless parser can construct an abstract syntax tree, and PEG-based tree
walkers and transformers can implement analysis and optimization passes on this tree, then either compiling
it to a target language or evaluating it. Using the same abstraction (PEGs) for the whole pipeline of simple
domain-specific languages can make them easier for programmers to design and implement.

Adding a few extra instructions to the parsing machine enables transformation of certain
pattern classes to more efficient programs, and we also present these optimizations. We
restrict ourselves to optimizations on list patterns, as our previous work has covered more general
parsing machine optimizations. For each optimization, we present a proof of its correctness and a benchmark
showing how effective it is.

We also present an extension to the PEG formalism to include lazy semantic actions, by which
we can extract useful information from structured data, instead of just knowing if it fits a pattern.
Our approach for semantic actions is lazy because the match does not execute the actions, only collects enough
information to execute them later (in a typical implementation, right after the match finishes). This also
means that semantic actions are free to have side-effects even in the presence of backtracking.

Finally, we review related work on parsing structured data and on semantic actions for PEGs. We also present another set
of benchmarks comparing our extended LPEG with a PEG-based tool of similar power, showing an order-of-magnitude
improvement.

The rest of this paper is organized as follows: Section~\ref{sec:machine} extends
PEGs with list patterns and describes the virtual parsing machine;
Section~\ref{sec:equivalence} proves the transformation between PEGs and their
corresponding programs for the machine is correct; Section~\ref{sec:optimizations}
describes optimizations for list patterns in our machine;
Section~\ref{sec:captures} extends PEGs with lazy semantic actions and shows how to execute them;
Section~\ref{sec:related} reviews some related work; finally,
Section~\ref{sec:conclusions} summarizes our results.

\section{Extending PEGs for Lists}
\label{sec:machine}

In~\cite{dls:lpeg}, we described a \texttt{match} relation for PEGs, 
where we defined the relation \texttt{match} on
$\mathrm{Grammar} \times \mathrm{Pattern} \times \Sigma^{*} \times \mathcal{N} \times (\mathcal{N} \cup \{\Nothing\})$.
Given a grammar (a map from variables to patterns), a pattern, a subject string, and a position (the subject starts at position $1$),
the relation gives us either the position after the match (possibly the length of the subject plus $1$) or \Nothing, depending on
whether the pattern matches the subject or not. We use 
$\Match{G}{p}{s}{i} \leadsto j$ to indicate that $(G, p, s, i, j) \in \texttt{match}$.

In this paper, we are considering lists to be List-style lists, made up from atoms and other lists. We will restrict ourselves
to only characters as atoms. We represent the empty list as \Emptyl. Lists are inductively defined by the operator \emph{:}
(also known as cons). If $c$ is an atom and $l$ is a list then $c:l$ is a list, and if $l_1$ and $l_2$ are lists then $l_1:l_2$ is
a list. The first argument of $:$ is the head of the list and the second is the tail. We will use $\{ e_1 e_2 \ldots e_n \}$ as
another way to write $e_1:e_2:\ldots :e_n:\Emptyl$.

We will use $|l|$ to represent the number of elements of list $l$, and its inductive definition is trivial. We will use $l[i]$ to
denote the $i^{th}$ element of the list, starting from $1$, which also has a straightforward inductive definition. List concatenation
is represented by juxtaposition ($l_1l_2$ is the list with all elements of $l_1$ followed by all elements from $l_2$, not to be
confused with $l_1:l_2$, which is a list with $l_1$ as the first element followed by the elements of $l_2$).

Now we can define a new relation $\texttt{match}_L$ on
$\mathrm{Grammar} \times \mathrm{Pattern} \times \mathrm{List} \times \mathcal{N} \times (\mathcal{N} \cup \{\Nothing\})$.
This relation gives us the position in the list after trying to match a pattern given a starting position and a grammar, or
\Nothing if the list does not match the pattern. As with \texttt{match}, we also have a notation
$\Matchl{G}{p}{s}{i} \leadsto j$ to indicate that $(G, p, s, i, j) \in \texttt{match}_L$.

Table~\ref{tab:patterns} presents the abstract syntax of PEG patterns with the new \emph{list pattern} $\{p\}$, and Figure~\ref{fig:semgr} presents an operational semantics of $\texttt{match}_L$ given as rules on the pattern structure. Except for rules $list.1$ and $list.2$, all semantic rules of $\texttt{match}_L$ are taken straight from \texttt{match}. We have that $\Matchl{G}{p}{s}{i} \leadsto j$ if we can use the rules to  build a finite derivation tree for this proposition.

%
\begin{table}
\centering
\begin{tabular}{|c|} \hline
\chmath{.}            $\in$ Pattern  \\ %\hline
\chmath{c}            $\in$ Pattern  \\ %\hline
If $(A, p)$ $\in$ Grammar then  $A$     $\in$ Pattern  \\ %\hline
If $p$   $\in$ Pattern then      
  $p^*$, $!p$, $\&p$, and $\{p\}$  $\in$ Pattern \\ %\hline	
If $p_{1}$ and $p_{2}$ $\in$ Pattern then
 $p_{1}p_{2}$ and $p_{1}/p_{2}$ $\in$ Pattern \\ \hline
\end{tabular}
\caption{Syntax of PEG patterns}
\label{tab:patterns}
\end{table}
%

Rules $list.1$ and $list.2$ formlalize the notion that a list pattern $\{p\}$ only succeeds if the current element of the
subject is also a list and if $p$ matches this whole sublist from the first element. Thus the pattern $\{ 'a' 'b' \}$ matches
the list $\{ \chmath{a} \chmath{b} \}$ but not the list $\{ \chmath{a} \chmath{b} \chmath{c} \}$, or the atom $\chmath{a}$.

The set of character strings is isomorphic to the set of lists where all elements are characters plus the empty list. Lets define $\Mapl$ as the natural mapping from strings to lists, that is, the empty string maps to the empty list, and a string $\chmath{c_1}\ldots \chmath{c_n}$ maps to $\{\chmath{c_1}\ldots \chmath{c_n}\}$. In other words, if $s$ is a string, $|s| = |\Mapl(s)|$ and
$s[i] = \Mapl(s)[i]$ for $1 < i \leq |s|$. We then have:
%
\begin{equation*}
\Matchf{G}{p}{s}{i} \leadsto j$ iff $\Matchl{G}{p}{\Mapl(s)}{i}.
\end{equation*}
%
with a trivial inductive proof on the height of the derivation tree, given the semantic rules are identical. In other words,
our extended semantics is identical to the regular PEG semantics when we are dealing with string-like lists as subjects.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Operational Semantics of PEG Patterns with Grammars and Lists %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure*}
{
\footnotesize
\begin{align*}
%Matching a given character
& \textbf{Character} \tenspaces 
{\frac{s[i] = \chmath{c}}{\Matchl{g}{\chmath{c}}{s}{i} \leadsto \Just{i+1}}} \mylabel{ch.1} \tenspaces
{\frac{s[i] \neq \chmath{c}}{\Matchl{g}{\chmath{c}}{s}{i} \leadsto \Nothing}} \mylabel{ch.2} \\ \\
%Matching any element
& \textbf{Any Element} \tenspaces
{\frac{i \leq |s|}{\Matchl{g}{.}{s}{i} \leadsto \Just{i+1}}} \mylabel{any.1} \tenspaces
{\frac{i > |s|}{\Matchl{g}{.}{s}{i} \leadsto \Nothing}} \mylabel{any.2} \\ \\
%Not
& \textbf{Not Predicate} \tenspaces \fivespaces
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Nothing} 
	{\Matchl{g}{!p}{s}{i} \leadsto \Just{i}}} \mylabel{not.1} \tenspaces
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Just{i+j}}
	{\Matchl{g}{!p}{s}{i} \leadsto \Nothing}} \mylabel{not.2} \\ \\
%And
& \textbf{And Predicate} \tenspaces \fivespaces
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Just{i+j}}
	{\Matchl{g}{\&p}{s}{i} \leadsto \Just{i}}} \mylabel{and.1} \tenspaces
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Nothing}
	{\Matchl{g}{\&p}{s}{i} \leadsto \Nothing}} \mylabel{and.2} \\ \\
%Concatenation
& \textbf{Concatenation} \twentyspaces
{\frac{\Matchl{g}{p_{1}}{s}{i} \leadsto \Just{i+j} \interf \Matchl{g}{p_{2}}{s}{i+j} \leadsto \Just{i+j+k}}
{\Matchl{g}{p_{1}p_{2}}{s}{i} \leadsto \Just{i+j+k}}} \mylabel{con.1} \\ \\
& \fivespaces
{\frac{\Matchl{g}{p_{1}}{s}{i} \leadsto \Just{i+j} \interf \Matchl{g}{p_{2}}{s}{i+j} \leadsto \Nothing}
	{\Matchl{g}{p_{1}p_{2}}{s}{i} \leadsto \Nothing}} \mylabel{con.2} \fivespaces
{\frac{\Matchl{g}{p_{1}}{s}{i} \leadsto \Nothing}
	{\Matchl{g}{p_{1}p_{2}}{s}{i} \leadsto \Nothing}} \mylabel{con.3} \\ \\
%Ordered Choice
& \textbf{Ordered Choice} \twentyspaces
{\frac{\Matchl{g}{p_{1}}{s}{i} \leadsto \Nothing \interf \Matchl{g}{p_{2}}{s}{i} \leadsto \Nothing}
	{\Matchl{g}{p_{1}/p_{2}}{s}{i} \leadsto \Nothing}} \mylabel{ord.1} \\ \\
& \fivespaces
{\frac{\Matchl{g}{p_{1}}{s}{i} \leadsto \Just{i+j}}
	{\Matchl{g}{p_{1}/p_{2}}{s}{i} \leadsto \Just{i+j}}} \mylabel{ord.2} \tenspaces
{\frac{\Matchl{g}{p_{1}}{s}{i} \leadsto \Nothing \interf \Matchl{g}{p_{2}}{s}{i} \leadsto \Just{i+k}}
	{\Matchl{g}{p_{1}/p_{2}}{s}{i} \leadsto \Just{i+k}}} \mylabel{ord.3} \\ \\ 
%Repetition
& \textbf{Repetition} \;\;\;
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Just{i+j} \interf \Matchl{g}{p^*}{s}{i+j} \leadsto \Just{i+j+k}}
	{\Matchl{g}{p^*}{s}{i} \leadsto \Just{i+j+k}}} \mylabel{rep.1} \;\;
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Nothing}
	{\Matchl{g}{p^*}{s}{i} \leadsto \Just{i}}} \mylabel{rep.2} \\ \\
%Variable
& \textbf{Variables} \twentyspaces
{\frac{\Matchl{g}{g(A_{k})}{s}{i} \leadsto \Just{i+j}}
	{\Matchl{g}{A_{k}}{s}{i} \leadsto \Just{i+j}}} \mylabel{var.1} \tenspaces
{\frac{\Matchl{g}{g(A_{k})}{s}{i} \leadsto \Nothing}
	{\Matchl{g}{A_{k}}{s}{i} \leadsto \Nothing}} \mylabel{var.2} \\ \\
%Closed Grammars
& \textbf{Closed Grammars} \tenspaces \fivespaces
{\frac{\Matchl{g}{g(A_{k})}{s}{i} \leadsto \Just{i+j}}
	{\Matchl{g^{\prime}}{(g,A_{k})}{s}{i} \leadsto \Just{i+j}}} \mylabel{cg.1} \tenspaces
{\frac{\Matchl{g}{g(A_{k})}{s}{i} \leadsto \Nothing}
	{\Matchl{g^{\prime}}{(g,A_{k})}{s}{i} \leadsto \Nothing}} \mylabel{cg.2} \\ \\
%Lists
& \textbf{List} \tenspaces
{\frac{\Matchl{g}{p}{s[i]}{1} \leadsto \Just{$|s[i]|$+ 1}}
	{\Matchl{g}{\{p\}}{s}{i} \leadsto \Just{i+1}}} \mylabel{list.1} \tenspaces
{\frac{\Matchl{g}{p}{s[i]}{1} \neq \Just{$|s[i]|$ + 1}}
	{\Matchl{g}{\{p\}}{s}{i} \leadsto \Nothing}} \mylabel{list.2}
\end{align*}
\caption{Operational Semantics of PEGs with Lists}
\label{fig:semgr}
}
\end{figure*}

\subsection{Parsing Machine}

In LPEG, our implementation of PEGs, each PEG pattern translates to a program,
which executes on a virtual parsing machine. The parsing machine has a state,
which changes according to the instructions of a program.

The machine has a program counter that addresses the next instruction to be executed,
a register that holds the current subject, another register that holds the current position
in the subject, and a stack that the machine uses for pushing return addresses, list
entries, and backtrack entries. A return address is just a new value for the program counter,
a list entry holds a subject and a position in the subject, and a backtrack entry holds an
address, the subject and a position in the subject.

In order to deal with lists, we are going to add the \texttt{Open} and \texttt{Close}
instructions to the machine's set of instructions presented in ~\cite{dls:lpeg}. Below
we have a description of these new instructions:

\texttt{Open}: changes the current subject and position, pushing on the stack
the previous values. The new current position is the beginning of the new
current subject.

\texttt{Close}: if the current position points to the end of the current subject,
this instruction pops the top entry from the stack, restoring the previous values
for the position and the subject, and then advances the position. If the current
position does not point to the end of the subject, a failure occurs. 

Figure~\ref{fig:semantics} presents the operational semantics of the parsing
machine as a relation between machine states. The program $\mathcal{P}$ that the
machine is executing is implicit. The state
is either a tuple $\mathcal{N} \times \mathrm{List} \times \mathcal{N} \times \mathrm{Stack}$,
containing the next instruction to execute (\emph{pc}), the current subject (\emph{s}),
the current position in the subject (\emph{i}), and a stack (\emph{e}), or $\Sfail{e}$,
a failure state with stack \emph{e}. Stacks are lists of
$(\mathcal{N} \times \mathrm{List} \times \mathcal{N}) \cup (\mathrm{List} \times \mathcal{N})
\cup \mathcal{N}$, where a stack position of form $\mathcal{N} \times \mathrm{List} \times \mathcal{N}$
represents a backtrack entry, a stack position of form $\mathrm{List} \times \mathcal{N}$ represents
a list entry, and a stack position of form $\mathcal{N}$ represents a return address.
The relation $\xrightarrow{\mathrm{Instruction}}$ relates two states when the instruction
addressed by \emph{pc} in the antecedent state matches the label, and the guard (if present)
is valid.
%
\begin{figure*}
{
\footnotesize
\[
\begin{array}{rlll}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{Char}{x}}%
      {\Sstate{pc+1}{s}{i+1}{e}}{\Subi=x}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{Char}{x}}%
      {\Sfail{e}}{\Subi\not=x}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{Any}{}}%
      {\Sstate{pc+1}{s}{i+1}{e}}{i+1 \leq |\Sub|}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{Any}{}}%
      {\Sfail{e}}{i+1 > |\Sub|}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{Choice}{l}}%
      {\Sstate{pc+1}{s}{i}{(pc+l,s,i):e}}{}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{Jump}{l}}%
      {\Sstate{pc+l}{s}{i}{e}}{}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{Call}{l}}%
      {\Sstate{pc+l}{s}{i}{(pc+1):e}}{}
\Sstep{\Sstate{pc}{s}{i}{pc_1:e}}{\Ia{Return}{}}%
      {\Sstate{pc_1}{s}{i}{e}}{}
\Sstep{\Sstate{pc}{s}{i}{h:e}}{\Ia{Commit}{l}}%
      {\Sstate{pc+l}{s}{i}{e}}{}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{Fail}{}}%
      {\Sfail{e}}{}
\Sstep{\Sfail{pc:e}}{\mbox{\emph{any}}}%
      {\Sfail{e}}{}
\Sstep{\Sfail{(s,i):e}}{\mbox{\emph{any}}}%
      {\Sfail{e}}{}
\Sstep{\Sfail{(pc,s,i):e}}{\mbox{\emph{any}}}%
      {\Sstate{pc}{s}{i}{e}}{}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{Open}{}}%
      {\Sstate{pc+1}{\Subi}{1}{(s,i):e}}{}
\Sstep{\Sstate{pc}{s}{i}{(s_1,i_1):e}}{\Ia{Close}{}}%
      {\Sstate{pc+1}{s_1}{i_1+1}{e}}{i=|\Sub|+1}
\Sstep{\Sstate{pc}{s}{i}{(s_1,i_1):e}}{\Ia{Close}{}}%
      {\Sfail{e}}{i\neq|\Sub|+1}
\end{array}
\]
}
\caption{Operational Semantics of the Parsing Machine}
\label{fig:semantics}
\end{figure*}



\section{Transforming Patterns to Programs}
\label{sec:equivalence}

The process of translating a pattern into a program is bottom up, and done at runtime.
The simplest patterns are translated to simple programs, and then
programs are combined according to rules specific for each PEG operation.
Programs are opaque entities for the translation process, the pattern
that originated them is not important, as long as the programs are
valid. In our implementation the process is fully incremental, and combining
programs is a simple matter of concatenating their texts.

In~\cite{dls:lpeg}, we represent this compilation process
using a transformation function $\mathrm{\Pi}$, which operates
on the domain $\mathrm{Grammar} \times \mathcal{N} \times \mathrm{Pattern}$,
where $\Pi(g,i,p)$ is the translation of pattern $p$ in the
context of grammar $g$ and with position $i$ relative to the
beginning of the closed grammar which contains it (if the pattern
is not part of a closed grammar then the value can be arbitrary).
We will also use the notation $|\Pi(g,i,p)|$, which
means the number of instructions of the program $\Pi(g,i,p)$.

The correctness of this transformation has already been proved
for the \texttt{match} relation. As this transformation
remains the same after the addition of lists, and we have
already proved Proposition~\ref{prop:match}, we just need
to prove the extra cases corresponding to rules $list.1$
and $list.2$ to prove that this transformation is also correct
for $\texttt{match}_L$.

Given a PEG grammar $g$, a position $i$ relative to the beginning of the grammar,
and a pattern $\{p\}$, we have the following transformation from pattern to the
virtual machine instructions:
%
\begin{equation*}
\begin{split}
\Pi(g, i, \{p\}) \equiv \;
	&{\tt Open} \\
	&\Pi(g, i+1, p)\\
	&{\tt Close}
\end{split}
\end{equation*}
%
The transformation for a list pattern $\{p\}$ just puts a pair of instructions \texttt{Open-Close}
around the pattern $p$.

The proof is an induction on the height of the proof tree given by the semantics of $\texttt{match}_L$.
What we are going to prove first is:
%
\begin{equation*}
\begin{split}
&\texttt{If } \Matchl{g}{\{p\}}{s}{i} = \Just{i+1} \texttt{ then}\\
&\Sstepp{\Sstate{pc}{s}{i}{e}}{\Pi(g,i,\{p\})}
	{\Sstate{pc + |\Pi(g,i,p)| + 2}{s}{i+1}{e}}{}
\end{split}
\end{equation*}
%
This case is related to the semantic rule $list.1$,
where the matching of element $i$ of a list
succeeds and matches the element entirely.
We have the following sequence of transitions:
%
\begin{align*}
\xrightarrow{Open} \; &
	{\Sstate{pc + 1}{s[i]}{1}{(s, i):e}} \\
\xrightarrow{\Pi(g, i+1, p)} \; &
	{\Sstate{pc + |\Pi(g,i,p)| + 1}{s[i]}{|s[i]|+1}{(s, i):e}} \\
\xrightarrow{Close} \; &
	{\Sstate{pc + |\Pi(g,i,p)| + 2}{s}{i+1}{e}}
\end{align*}
%
After the \texttt{Open} instruction, the subject becomes
$s[i]$, and the current position is $1$. By induction
we know the execution of $\Pi(g, i+1, p)$ leads to
$\Sstate{pc + |\Pi(g,i,p)| + 1}{s[i]}{|s[i]|+1}{(s, i):e}$,
and after the \texttt{Close} instruction we reach the final
state $\Sstate{pc + |\Pi(g,i,p)| + 2}{s}{i+1}{e}$.


We also need to prove that:
%
\begin{equation*}
\begin{split}
&\texttt{If } \Matchl{g}{\{p\}}{s}{i} = \Nothing \texttt{ then}\\
&\Sstepp{\Sstate{pc}{s}{i}{e}}{\Pi(g,i,\{p\})}
	{\Sfail{e}}{}
\end{split}
\end{equation*}
%
This case is related to the semantic rule $list.2$,
where the matching of element $i$ of a list
fails or does not match the element entirely.
Considering $n^\prime < |s[i]|+1$,  if the
matching of $p$ succeeds and results in $n^\prime$,
we have the following sequence of transitions:
%
\begin{align*}
\xrightarrow{Open} \; &
	{\Sstate{pc + 1}{s[i]}{1}{(s, i):e}} \\
\xrightarrow{\Pi(g, i+1, p)} \; &
	{\Sstate{pc + |\Pi(g,i,p)| + 1}{s[i]}{n^\prime}{(s, i):e}} \\
\xrightarrow{Close} \; &
	{\Sfail{e}}{}
\end{align*}
%
As $n^\prime < |s[i]|+1$ the execution of the \texttt{Close}
instruction leads the machine to a failure state.

There is also the case where the matching of $p$ fails, leading
the machine to a failure state $\Sfail{e}$ too.


\section{Optimizations}
\label{sec:optimizations}

The previous section showed how to compile list patterns to our parsing machine, and proved the
correctness of this transformation. In several cases, though, we can make the resulting program more efficient,
avoiding unecessary pushs and pops on the machine's stack. This section shows another way
of compiling some list patterns by using pattern identities and a few extra machine instructions, generating
more efficient programs.

Figure~\ref{fig:optimizations} lists the instructions we are adding to the machine and their
semantics. Let's start with a very common pattern, $\{ c_{1} \ldots c_{n} \}$, that is, a pattern that
matches a list of $n$ characters. The current program for this pattern is an \texttt{Open} instruction
followed by a sequence of \texttt{Char} instructions and a \texttt{Close} instruction. We can
compile this pattern to a single \texttt{String} instruction with the string ``$c_{1} \ldots c_{2}$'' as its 
argument.

%
\begin{figure*}
{\footnotesize
\[
\begin{array}{rlll}
\Sstep{ \Sstate{pc}{s}{i}{e} }{ \Ia{String}{x} }{ \Sstate{pc+1}{s}{i+1}{e} }{ s[i] = \Mapl(x) }
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{String}{x}}%
      {\Sfail{e}}{s[i] \neq \Mapl(x)}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Iaa{TestString}{l}{x}}%
      {\Sstate{pc+1}{s}{i+1}{e}}{s[i] = \Mapl(x)}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Iaa{TestString}{l}{x}}%
      {\Sstate{pc+l}{s}{i}{e}}{s[i] \neq \Mapl(x)}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{NotAny}{}}%
      {\Sstate{pc+1}{s}{i}{e}}{i > |s|}
\Sstep{\Sstate{pc}{s}{i}{e}}{\Ia{NotAny}{}}%
      {\Sfail{e}}{i \leq |s|}
\end{array}
\]
}
\caption{Operational Semantics of Specialized Instructions for Lists}
\label{fig:optimizations}
\end{figure*}

Now that we have a single instruction that matches a whole list of characters (a list that is isomorphic to a string),
we can do \emph{head-fail} optimizations on these tests by having a complementary \texttt{TestString} instruction
that jumps to a label instead of failing if it does not match. This kind of failure is very common when we
have a pattern like $\{ c_{1} \ldots c_{n} \} p_1 / p_2$, such as when matching against a tree that uses strings in the
first element as tags. We can avoid pushing a backtrack entry that will be discarded most of the time
when trying to match the tag. The compilation for the pattern above becomes:
%
\begin{equation*}
\begin{split}
\Pi(g,x, \{c_{1} \ldots c_{n} \} p_1 / p_{2}) \equiv \;
	&{\tt TestString} \; |\Pi(g,x,p_{1})| + 3 \;\; c_1 \ldots c_n  \\
	&{\tt Choice} \; |\Pi(g,x,p_{1})| + 2 \;\;\; 1\\
	&\Pi(g,x+2,p_{1})\\
	&{\tt Commit } \; |\Pi(g,x,p_{2})| + 1\\
	&\Pi(g,x+|\Pi(g,x,p_1)|+3,p_{2})
\end{split}
\end{equation*}
%
Notice that now the \texttt{Choice} instruction takes an offset, which is subtracted from the current position
when pushing a new backtrack entry. An offset of zero is assumed if an offset is not provided.

In case of an unsuccessful match of $\{c_1 \ldots c_n\}$ and a successful
match of $p_2$, we have the following sequence of transitions:
\begin{align*}
\xrightarrow{TestString} &
	{\Sstate{pc + |\Pi(g,x,p_{1})| + 3}{s}{i}{e}} \\
\xrightarrow{\Pi(g,x+|\Pi(g,x,p_1)|+3,p_{2})} &
    {\Sstate{pc + |\Pi(g,x, \{c_1 \dots c_n \} p_1 / p_2)|}{s}{i+k}{e}}
\end{align*}
which is correct by induction on the correctness of $p_{2}$'s compilation.

Finally, there is an interesting optimization derived from an identity between patterns. The natural way
of writing a choice between two list patterns is $\{p_1\} / \{p_2\}$. This compiles to a \texttt{Choice} followed by
an \texttt{Open} instruction, followed by the compilation of $p_1$, then a \texttt{Commit}, another \texttt{Open}, the compilation
of $p_2$, and a final \texttt{Close} instruction. But when $p_1$ fails we end up trying to match $p_2$ against the same subject,
and we have an unecessary stack pop and push (plus unecessary changes of the current subject, which can have implementation
costs). The naive optimization is to transform this pattern to $\{ p_1 / p_2 \}$, but now if $p_1$ is a partial match and $p_2$ is a
full match the new pattern will fail where the previous one would succeed. We can correct this by transforming the original
pattern to $\{ p_1 !. / p_2 \}$.

Now a partial match of $p_1$ will fail the antecedent of the choice, and if $p_2$ is a full match then the whole pattern succeeds,
as in the original. By using the new \texttt{NotAny} instruction to compile $!.$, the new pattern compiles to:
%
\begin{equation*}
\begin{split}
\Pi(g, x, \{ p_1 !. / p_2\}) \equiv \;
	&{\tt Open} \;  \\
	&{\tt Choice} \; |\Pi(g,x,p_1)| + 3 \\
	&\Pi(g, x+2, p_1)\\
	&{\tt NotAny } \; \\
	&{\tt Commit } \; |\Pi(g,x,p_2)| + 1\\
	&\Pi(g, x + |\Pi(g,x,p_1)| + 4, p_2) \\
	&{\tt Close} \; 
\end{split}
\end{equation*}
%
Which avoids the extra work of the original pattern, and incidentally opens the patterns to further head-fail optimization. 
A full proof of the identity, and the correctness of compiling $!.$ to \texttt{NotAny}, are straightforward inductions on
derivation trees.

We have implemented these optimizations on LPEG, and evaluated their effectiveness on a few simple benchmarks. The
results are summarized on Figure~\ref{fig:microbench}. The graph shows the running time of the benchmarks for
the base LPEG, LPEG with the string optimization, and LPEG with the string and list choice optimization. 
The benchmarks are on the vertical axis: the \emph{string} benchmark uses a concatenation of string-like
patterns (150,000 iterations), the \emph{headfail} benchmark uses an ordered choice of these patterns (15,000 iterations), and the \emph{choice} benchmark uses an ordered choice of lists of string-like patterns (40,000 iterations). The benchmarks with ordered choice use subjects that match each alternative of the choice.

% TODO: add graph here

\section{Captures}
\label{sec:captures}

In LPEG, a capture is a mix of conventional captures with semantic
actions. In order to add captures, we need to change the $\texttt{match}_L$
relation, which now becomes:
$\mathrm{Grammar} \times \mathrm{Pattern} \times \mathrm{List} \times \mathcal{N} \times ((\mathcal{N}, Capture^*) \cup \{\Nothing\})$,
where $Capture^*$ represents a list of captures.
%We will use the notation
%$\Matchl{G}{p}{s}{i} \leadsto (j,c)$ to indicate that $(G, p, s, i, (j, c)) \in \texttt{match}_L$.

The use of captures does not affect the matching of a subject, if a matching was successful without the
use of captures, it will still be successful if we do it again using captures. Therefore, the use of capture
patterns, whose syntax is listed in Table~\ref{tab:captures}, will only affect the list of captures.

We have four kinds of captures: \emph{simple}, which captures a given portion of the subject;
\emph{constant}, which creates a constant capture; \emph{function}, which calls a given function
with a list of values obtained from the captures; and \emph{fold}, which folds (or reduces) a list
of values, producing a single value.
%
\begin{table}
\centering
\begin{tabular}{|c|} \hline
If $v$ $\in$ Value then $\Pcap{const}{v}$ $\in$ Pattern  \\ %\hline
If $p$ $\in$ Pattern then $\Pcap{simp}{p}$ $\in$ Pattern  \\ %\hline
If $p$ $\in$ Pattern and $f$ $\in$ $Value^* \times Value^*$ then $\Pcap{func}{f}$ $\in$ Pattern \\ %\hline
If $p$ $\in$ Pattern and $f$ $\in$ $Value \times Value \times Value$ then $\Pcap{fold}{f}$ $\in$ Pattern \\ \hline
\end{tabular}
\caption{Syntax of Capture Patterns}
\label{tab:captures}
\end{table}
%
Figure~\ref{fig:captures} presents the new operational semantics of $\texttt{match}_L$ when dealing with captures.
As the semantics of $\texttt{match}_L$ remains the same when a pattern fails, we did not repeat the rules related
to an unsuccessful matching for the previous patterns. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Operational Semantics of PEG with Captures %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{figure*}
{
\footnotesize
\begin{align*}
%Matching a given character
& \textbf{Character} \fivespaces 
{\frac{s[i] = \chmath{c}}{\Matchl{g}{\chmath{c}}{s}{i} \leadsto \Justc{i+1}{\Emptyl}}} \mylabel{ch.1} \fivespaces
%Matching any element
\textbf{Any Element} \fivespaces
{\frac{i \leq |s|}{\Matchl{g}{.}{s}{i} \leadsto \Justc{i+1}{\Emptyl}}} \mylabel{any.1}  \\ \\
%Not
& \textbf{Not Predicate} \fivespaces
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Nothing} 
	{\Matchl{g}{!p}{s}{i} \leadsto \Justc{i}{\Emptyl}}} \mylabel{not.1} \fivespaces
%And
\textbf{And Predicate} \fivespaces
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Justc{i+j}{c}}
	{\Matchl{g}{\&p}{s}{i} \leadsto \Justc{i}{c}}} \mylabel{and.1}  \\ \\
%Concatenation
& \textbf{Concatenation} \twentyspaces
{\frac{\Matchl{g}{p_{1}}{s}{i} \leadsto \Justc{i+j}{c_1} \interf \Matchl{g}{p_{2}}{s}{i+j} \leadsto \Justc{i+j+k}{c_2}}
{\Matchl{g}{p_{1}p_{2}}{s}{i} \leadsto \Justc{i+j+k}{c_1 \Concatl c_2}}} \mylabel{con.1} \\ \\
%Ordered Choice
& \textbf{Ordered Choice} \;
{\frac{\Matchl{g}{p_{1}}{s}{i} \leadsto \Justc{i+j}{c_1}}
	{\Matchl{g}{p_{1}/p_{2}}{s}{i} \leadsto \Justc{i+j}{c_1}}} \mylabel{ord.2} \;
{\frac{\Matchl{g}{p_{1}}{s}{i} \leadsto \Nothing \;\;\; \Matchl{g}{p_{2}}{s}{i} \leadsto \Justc{i+k}{c_2}}
	{\Matchl{g}{p_{1}/p_{2}}{s}{i} \leadsto \Justc{i+k}{c_2}}} \mylabel{ord.3} \\ \\ 
%Repetition
& \textbf{Repetition} \;\;
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Justc{i+j}{c} \interf \Matchl{g}{p^*}{s}{i+j} \leadsto \Justc{i+j+k}{c_1}}
	{\Matchl{g}{p^*}{s}{i} \leadsto \Justc{i+j+k}{c \Concatl c_1}}} \mylabel{rep.1} \;\;
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Nothing}
	{\Matchl{g}{p^*}{s}{i} \leadsto \Justc{i}{\Emptyl}}} \mylabel{rep.2} \\ \\
%Variable
& \textbf{Variables} \fivespaces
{\frac{\Matchl{g}{g(A_{k})}{s}{i} \leadsto \Justc{i+j}{c}}
	{\Matchl{g}{A_{k}}{s}{i} \leadsto \Justc{i+j}{c}}} \mylabel{var.1} \fivespaces
%Closed Grammars
\textbf{Closed Grammars} \fivespaces
{\frac{\Matchl{g}{g(A_{k})}{s}{i} \leadsto \Justc{i+j}{c}}
	{\Matchl{g^{\prime}}{(g,A_{k})}{s}{i} \leadsto \Justc{i+j}{c}}} \mylabel{cg.1} \tenspaces \\ \\
%Lists
& \textbf{List} \;\;
{\frac{\Matchl{g}{p}{s[i]}{1} \leadsto \Justc{$|s[i]|$ + 1}{c}}
	{\Matchl{g}{\{p\}}{s}{i} \leadsto \Justc{i+1}{c}}} \mylabel{list.1} \;\;\;
%Matching a Constant Capture
\textbf{Const Capture} \;\;
{\frac{}
	{\Matchl{g}{\Pcap{const}{v}}{s}{i} \leadsto \Justc{i}{\{\Pcap{const}{v}\}}}} \mylabel{const.1} \\ \\
%Matching a Simple Capture
& \textbf{Simple Capture} \tenspaces
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Nothing}
	{\Matchl{g}{\Pcap{simp}{p}}{s}{i} \leadsto \Nothing}} \mylabel{simple.2} \\ \\
& \tenspaces
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Justc{i+j}{c}}
	{\Matchl{g}{\Pcap{simp}{p}}{s}{i} \leadsto \Justc{i+j}{(\Pcapp{simp}{s}{i}):c \Concatl \{\Pcap{close}{j}\}}}} \mylabel{simple.1} \\ \\
%Matching a Function Capture
& \textbf{Function Capture} \tenspaces
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Nothing}
	{\Matchl{g}{\Pcap{func}{f}}{s}{i} \leadsto \Nothing}} \mylabel{func.2} \\ \\
& \tenspaces
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Justc{i+j}{c}}
	{\Matchl{g}{\Pcap{func}{f}}{s}{i} \leadsto \Justc{i+j}{\Pcap{func}{f} \Concatl c \Concatl \{\Pcap{close}{j}\}}}} \mylabel{func.1} \\ \\
%Matching a Fold Capture
& \textbf{Fold Capture} \;
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Nothing}{\Matchl{g}{\Pcap{fold}{f}}{s}{i} \leadsto \Nothing}} \mylabel{fold.2}
\;
{\frac{\Matchl{g}{p}{s}{i} \leadsto \Justc{i+j}{c}}{\Matchl{g}
	{\Pcap{fold}{f}}{s}{i} \leadsto \Justc{i+j}{\Pcap{fold}{f}:c \Concatl \{\Pcap{close}{j}\}}}} \mylabel{fold.1}
\end{align*}
\caption{Operational Semantics of PEG Patterns with Captures}
\label{fig:captures}
}
\end{figure*}

Accordingly, we also need to change the state of the parsing machine and to add new instructions
to deal with captures. The state of our machine is now either a tuple
$\mathcal{N} \times \mathrm{List} \times \mathcal{N} \times \mathrm{Stack} \times \mathrm{Capture^*}$,
where we will use a symbol \emph{k} to denote the list of captures, or $\Sfail{e}$.
Now, a backtrack entry keeps also a list of captures.

\begin{figure*}
{
\footnotesize
\[
\begin{array}{rlll}
\Sstep{\Sstatec{pc}{s}{i}{e}{k}}{\Iaa{Choice}{l}{o}}%
      {\Sstatec{pc+1}{s}{i}{(pc+l,s,i-o,k):e}{k}}{}
\Sstep{\Sfail{(pc,s,i,k):e}}{\mbox{\emph{any}}}%
      {\Sstatec{pc}{s}{i}{e}{k}}{}
\Sstep{\Sstatec{pc}{s}{i}{e}{k}}{\Ia{ConstCap}{v}}%
      {\Sstatec{pc+1}{s}{i}{e}{k \Concatl \{\Pcap{const}{v}\}}}{}
\Sstep{\Sstatec{pc}{s}{i}{e}{k}}{\Ia{SimpCap}{p}}%
      {\Sstatec{pc+1}{s}{i}{e}{k \Concatl \{\Pcapp{simp}{s}{i}\}}}{}
\Sstep{\Sstatec{pc}{s}{i}{e}{k}}{\Ia{FuncCap}{v}}%
      {\Sstatec{pc+1}{s}{i}{e}{k \Concatl \{\Pcap{func}{f}\}}}{}
\Sstep{\Sstatec{pc}{s}{i}{e}{k}}{\Ia{FoldCap}{v}}%
      {\Sstatec{pc+1}{s}{i}{e}{k \Concatl \{\Pcap{fold}{f}\}}}{}
\Sstep{\Sstatec{pc}{s}{i}{e}{k}}{\Ia{CloseCap}{}}%
      {\Sstatec{pc+1}{s}{i}{e}{k \Concatl \{\Pcap{close}{i}\}}}{}
\end{array}
\]
}
\caption{Operational Semantics of the Parsing Machine using Captures}
\label{fig:semcaptures}
\end{figure*}

The new instructions of the parsing machine are:
\texttt{ConstCap}, which pushes a constant capture on the list of captures;
\texttt{SimpCap}, which pusches a simple capture;
\texttt{FuncCap}, which pushes a function capture;
\texttt{FoldCap}, which pushes a fold capture;
and \texttt{CloseCap}, which pushes an entry indicating the end of a capture;
Figure~\ref{fig:semcaptures} presents the semantics of these new instructions, plus the new semantics of
\texttt{Choice} and \texttt{Fail} when there is backtrack entry on the top of the stack.

The compilation of a pattern $\Pcap{const}{v}$, just produces an instruction $ConstCap \; v$. The compilation
of a pattern $\Pcap{simp}{p}$, puts a pair of instructions $SimpCap-CloseCap$ around the program corresponding
to pattern $p$. The compilation of $\Pcap{func}{f}$ and $\Pcap{fold}{f}$ is similar.

\subsection{Evaluating the List of Captures}

After the matching, the list of captures is evaluated in order to produce
the actual values.

In case of a constant capture, the final value is already on the list of
captures. In case of a simple capture, the final value is the slice from $i$ until $j-1$ of the subject
$s$. In case of a function capture, the function $f$ is called and receives as its parameters the values
produced from a list of captures. The values returned by $f$ are the final values of that list of captures.

In case of a fold capture, the $f$ function will be called with the values produced from a list of captures.
If the evaluation of a list of captures produces values $v_1, v_2, \ldots, v_n$, we have that
$fold f v_1, v_2, \ldots, v_n$ will produce the value: $f(\ldots f(f(v_1,v_2), v_3) \ldots,v_n)$.
If the list of values has just one value, then the result of $fold f v_1$ is $v_1$. If the list
is empty, the result is unspecified.

The \texttt{eval} function and its auxiliary functions do the job of evaluating a list of captures. The
definition of \texttt{eval} is: $\mathrm{State} \times \mathrm{State}$, where $State$ is a pair
$(\mathrm{Capture^*}, \mathrm{Value^*})$, where $Capture^*$ is a list of captures and $Value$ a list of values.

Functions \texttt{esimp}, \texttt{efunc}, and \texttt{efold} are similar to \texttt{eval}, but get also an
extra state. In case of \texttt{esimp}, the extra state is a tuple $(\mathrm{Subject}, \mathcal{N}, \mathrm{Capture^*})$.
In case of \texttt{efunc} and \texttt{efold}, the extra state is a tuple $(\mathrm{Function}, \mathrm{Capture^*})$.
In all tuples, $Capture^*$ is the list of captures until the beginning of the corresponding capture.
After applying \texttt{eval} to the list of captures constructed by $\mathrm{match}_L$ and an empty list of values,
the result is an empty list of captures and a list of values obtained from the captures.
Notice that the position associated with a close capture is only important when evaluating a simple capture.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Operational Semantics of eval %%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure*}[t]
{
\footnotesize
\begin{align*}
%Not
& %\textbf{eval} \tenspaces
{\frac{}
	{\Eval{(\Emptyl,v)} = (\Emptyl,v)}}  \mylabel{eval.1} \tenspaces 
{\frac{}
	{\Eval{(\Pcap{close}{j}:cs, vs)} = (\Pcap{close}{j}:cs, vs)}} \mylabel{eval.2} \\ \\
%
& {\frac{\Eval{(cs, vs \Concatl \{v\})} = (cs_1, vs_1)}
	{\Eval{(\Pcap{const}{v}:cs, vs)} = (cs_1, vs_1)}} \mylabel{eval.3} \tenspaces
{\frac{\Esimple{(s,i,vs)}{(cs, \Emptyl)} = (cs_1, vs_1)}
	{\Eval{(\Pcap{simp}{s}{i}:cs, vs)} = (cs_1, vs_1)}} \mylabel{eval.4} \\ \\
%
& {\frac{\Efunction{(f,vs)}{(cs, \Emptyl)} = (cs_1, vs_1)}
	{\Eval{(\Pcap{func}{f}:cs, vs)} = (cs_1, vs_1)}} \mylabel{eval.5} \tenspaces
{\frac{\Efold{(f,vs)}{(cs, \Emptyl)} = (cs_1, vs_1)}
	{\Eval{(\Pcap{fold}{f}:cs, vs)} = (cs_1, vs_1)}} \mylabel{eval.6} \\ \\
%
& %\textbf{evsimple} \tenspaces 
{\frac{\Eval{(cs, vs)} = (cs_2, vs_2)}
	{\Esimple{(s,i,vs_1)}{(\Pcap{close}{j}:cs, vs)} = (cs_2, vs_1 \Concatl (sub(s, i, j)):vs_2)}} \mylabel{esimp.1} \\ \\
& {\frac{\Eval{(c:cs, \Emptyl)} = (\Pcap{close}{j}:cs_2, vs_2) \;\;\; \Esimple{(s,i,vs_1)}{(\Pcap{close}{j}:cs_2,vs_2)} = (cs_3, vs_3)}
	{\Esimple{(s,i,vs_1)}{(c:cs, vs)} = (cs_3, vs_3)}}  \, ,c \neq (\Pcap{close}{j}) \mylabel{esimp.2} \\ \\
%
& %\textbf{evfunc} \tenspaces 
{\frac{\Eval{(cs, \Emptyl)} = (cs_2, vs_2)}
	{\Efunction{(f,vs_1)}{(\Pcap{close}{j}:cs, vs)} = (cs_2, vs_1 \Concatl \{f (vs)\} \Concatl vs_2)}} \mylabel{efunc.1} \\ \\
& {\frac{\Eval{(c:cs, \Emptyl)} = (\Pcap{close}{j}:cs_2, vs_2) \;\;\; \Efunction{(f,vs_1)}{(\Pcap{close}{j}):cs_2),vs_2)} = (cs_3, vs_3)}
	{\Efunction{(f,vs_1)}{(c:cs, vs)} = (cs_3, vs_3)}}  \; ,\,c \neq \Pcap{close}{j} \mylabel{efunc.2} \\ \\
%
& %\textbf{evfold} \tenspaces 
{\frac{\Eval{(cs, \Emptyl)} = (cs_2, vs_2)}
	{\Efold{(f,vs_1)}{(\Pcap{close}{j}:cs, vs)} = (cs_2, vs_1 \Concatl (fold (f, vs)):vs_2)}} \mylabel{efold.1} \\ \\
& {\frac{\Eval{(c:cs, \Emptyl)} = (\Pcap{close}{j}:cs_2, vs_2) \;\;\; \Efunction{(f,vs_1)}{(\Pcap{close}{j}:cs_2),vs_2)} = (cs_3, vs_3)}
	{\Efold{(f,vs_1)}{(c:cs, vs)} = (cs_3, vs_3)}}  \; ,\,c \neq \Pcap{close}{j}) \mylabel{efold.2}
\end{align*}
}
\caption{Operational Semantics of \texttt{eval}, \texttt{esimp}, \texttt{efunc}, and \texttt{efold}}
\label{fig:eval}
\end{figure*}




\section{Related Work}
\label{sec:related}


\section{Conclusions}
\label{sec:conclusions}

Based on the work of ~\cite{warth:ometa}, we have presented an extension of PEGs which
allows the matching of lists, instead of just characters. According, we have also extended
the definition of our virtual parsing machine for PEGs, and we have proved the transformation
from extended PEG patterns to programs in our parsing machine is correct.

We also added new list-specific instructions to the parsing machine, in order to improve its
performance when dealing with lists.

To perform semantic actions, we extended the semantics of the $\mathrm{match}_L$ relation, adding
new patterns related to the capture of values. During the matching, our machine does not perform
semantic actions, it only gathers enough information about the captures so that after the matching
it can produce the corresponding values.

We have shown the implementation of our parsing machine for PEGs and its list extension is really fast.
When compared with OMeta, which also implements an extension of PEGs which supports the matching of lists,
the performance of LPEG is almost $10$ times better. 
\bibliographystyle{sbc}
\bibliography{sblp} 


\end{document}
